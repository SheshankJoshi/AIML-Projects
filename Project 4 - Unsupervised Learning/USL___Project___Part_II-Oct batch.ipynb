{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "USL_-_Project_-_Part_II.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgHIkWmkGaN9"
      },
      "source": [
        "\n",
        "\n",
        "Explaining the right approach and techniques to be used to solve the problem.\n",
        "\n",
        "Approach:\n",
        "- Clustering can be employed to ignore the target class. Use the restof the data to form clusters. Using these clusters we can impute the missing values from the target class only if the new cluster pattern matches that of actual target class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnTOvblPGaN-"
      },
      "source": [
        "# Import the dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df=pd.read_excel(\"Company.xlsx\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qowIdHoIGaN_"
      },
      "source": [
        "# Use K Means or Hierarchical clustering to find out the optimal number of clusters in the data.\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "# We are dropping car name. We could try label encoder or some text \n",
        "# preprocessing techniques to extract unique values\n",
        "df_final = df.drop(['Quality'],axis=1) \n",
        "\n",
        "# We are making use of cdsit function to calculate errors.\n",
        "# Kmeans.inertia_ can also be used here\n",
        "distortions = []\n",
        "K = range(1,10)\n",
        "for k in K:\n",
        "    kmeanModel = KMeans(n_clusters=k).fit(df_final)\n",
        "    kmeanModel.fit(df_final)\n",
        "    distortions.append(\n",
        "        sum(np.min(cdist(df_final, \n",
        "                   kmeanModel.cluster_centers_, 'euclidean'), \n",
        "                   axis=1)) / df_final.shape[0])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(K, distortions, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Distortion')\n",
        "plt.title('The Elbow Method showing the optimal k')\n",
        "plt.show()\n",
        "\n",
        "# Kmeans \n",
        "\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(df_final)\n",
        "kmeans.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nWh_u21GaN_"
      },
      "source": [
        "# Transfer to dataset\n",
        "df['clusters']=kmeans.labels_\n",
        "df.to_excel(\"Prediction.xlsx\")  # predictions marked on the excel file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdCpjS4PGaOA"
      },
      "source": [
        "                                             END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zz97oXqGaOA"
      },
      "source": [
        "_________________________________________________________________\n",
        "\n",
        "Â©Great Learning. Proprietary content. All Rights Reserved. Unauthorised use or distribution prohibited\n",
        "________________________________________________________"
      ]
    }
  ]
}