{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec55c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "import ipyparallel as ipp\n",
    "import time\n",
    "\n",
    "c=ipp.Client()\n",
    "\n",
    "dview=c[:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f2fb75",
   "metadata": {},
   "source": [
    "**Note**\n",
    "First I attempted here to download the data directly from the internet but later imported it directly from the pre-established from the Tensorflow itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b40dfb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "C:\\Users\\Sheshank_Joshi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\Sheshank_Joshi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test)=k.datasets.imdb.load_data(path=\"imdb.npz\",num_words=10000,maxlen=100,seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac3c5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 18, 783, 254, 4424, 6477, 451, 64, 50, 26,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 14, 840, 4607, 20, 9, 99, 8762, 18, 1155, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 6, 2096, 200, 14, 20, 5, 1065, 236, 2, 9, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 14, 9, 31, 7, 4, 118, 7, 4, 201, 2, 56, 50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 25, 144, 124, 15, 13, 244, 4, 552, 7, 415,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>[1, 48, 335, 11, 4, 1310, 18, 49, 8655, 641, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>[1, 32, 14, 740, 44, 14, 112, 6, 78, 20, 9, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>[1, 972, 39, 4, 644, 2118, 7, 4, 6227, 5090, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>[1, 54, 13, 645, 8, 106, 14, 20, 23, 2, 300, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>[1, 48, 25, 40, 204, 5565, 6147, 2129, 25, 80,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2773 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     [1, 18, 783, 254, 4424, 6477, 451, 64, 50, 26,...\n",
       "1     [1, 14, 840, 4607, 20, 9, 99, 8762, 18, 1155, ...\n",
       "2     [1, 6, 2096, 200, 14, 20, 5, 1065, 236, 2, 9, ...\n",
       "3     [1, 14, 9, 31, 7, 4, 118, 7, 4, 201, 2, 56, 50...\n",
       "4     [1, 25, 144, 124, 15, 13, 244, 4, 552, 7, 415,...\n",
       "...                                                 ...\n",
       "2768  [1, 48, 335, 11, 4, 1310, 18, 49, 8655, 641, 7...\n",
       "2769  [1, 32, 14, 740, 44, 14, 112, 6, 78, 20, 9, 18...\n",
       "2770  [1, 972, 39, 4, 644, 2118, 7, 4, 6227, 5090, 2...\n",
       "2771  [1, 54, 13, 645, 8, 106, 14, 20, 23, 2, 300, 1...\n",
       "2772  [1, 48, 25, 40, 204, 5565, 6147, 2129, 25, 80,...\n",
       "\n",
       "[2773 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007441c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2773 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     1\n",
       "4     0\n",
       "...  ..\n",
       "2768  0\n",
       "2769  1\n",
       "2770  1\n",
       "2771  1\n",
       "2772  1\n",
       "\n",
       "[2773 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8c90b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 23, 4, 1927, 499, 12, 1054, 198, 4, 64, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 13, 92, 124, 51, 4, 1188, 7, 14, 22, 71, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 710, 910, 22, 44, 6, 1170, 1475, 37, 2507,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 48, 25, 235, 40, 3121, 2, 234, 23, 6, 22, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 13, 219, 14, 159, 3821, 33, 4, 2, 22, 1413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>[1, 13, 244, 131, 24, 252, 51, 4, 609, 14, 20,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>[1, 13, 264, 15, 14, 16, 424, 8, 30, 1621, 42,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>[1, 13, 28, 210, 77, 6, 666, 337, 7, 6071, 113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>[1, 160, 503, 20, 18, 2369, 448, 1424, 23, 168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>[1, 13, 119, 14, 20, 31, 7, 61, 32, 58, 2635, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2963 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     [1, 23, 4, 1927, 499, 12, 1054, 198, 4, 64, 15...\n",
       "1     [1, 13, 92, 124, 51, 4, 1188, 7, 14, 22, 71, 2...\n",
       "2     [1, 710, 910, 22, 44, 6, 1170, 1475, 37, 2507,...\n",
       "3     [1, 48, 25, 235, 40, 3121, 2, 234, 23, 6, 22, ...\n",
       "4     [1, 13, 219, 14, 159, 3821, 33, 4, 2, 22, 1413...\n",
       "...                                                 ...\n",
       "2958  [1, 13, 244, 131, 24, 252, 51, 4, 609, 14, 20,...\n",
       "2959  [1, 13, 264, 15, 14, 16, 424, 8, 30, 1621, 42,...\n",
       "2960  [1, 13, 28, 210, 77, 6, 666, 337, 7, 6071, 113...\n",
       "2961  [1, 160, 503, 20, 18, 2369, 448, 1424, 23, 168...\n",
       "2962  [1, 13, 119, 14, 20, 31, 7, 61, 32, 58, 2635, ...\n",
       "\n",
       "[2963 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb084cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2963 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     1\n",
       "...  ..\n",
       "2958  0\n",
       "2959  0\n",
       "2960  1\n",
       "2961  0\n",
       "2962  1\n",
       "\n",
       "[2963 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "361636eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2773,)\n",
      "(2773,)\n",
      "(2963,)\n",
      "(2963,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a6168d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56323f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Train Set\")\n",
    "sns.countplot(x=pd.Series(y_train))\n",
    "#plt.show()\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Test Set\")\n",
    "sns.countplot(x=y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197139e2",
   "metadata": {},
   "source": [
    "The Set is completely balanced and finished here in terms of proper class balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02bf9acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "066d36dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "C:\\Users\\Sheshank_Joshi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\Sheshank_Joshi\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test)=imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a367c8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "414d7316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "dictionary=imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6976613",
   "metadata": {},
   "source": [
    "let us now check for what the first sentence means in translated terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7422025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fawn': 34701,\n",
       " 'tsukino': 52006,\n",
       " 'nunnery': 52007,\n",
       " 'sonja': 16816,\n",
       " 'vani': 63951,\n",
       " 'woods': 1408,\n",
       " 'spiders': 16115,\n",
       " 'hanging': 2345,\n",
       " 'woody': 2289,\n",
       " 'trawling': 52008,\n",
       " \"hold's\": 52009,\n",
       " 'comically': 11307,\n",
       " 'localized': 40830,\n",
       " 'disobeying': 30568,\n",
       " \"'royale\": 52010,\n",
       " \"harpo's\": 40831,\n",
       " 'canet': 52011,\n",
       " 'aileen': 19313,\n",
       " 'acurately': 52012,\n",
       " \"diplomat's\": 52013,\n",
       " 'rickman': 25242,\n",
       " 'arranged': 6746,\n",
       " 'rumbustious': 52014,\n",
       " 'familiarness': 52015,\n",
       " \"spider'\": 52016,\n",
       " 'hahahah': 68804,\n",
       " \"wood'\": 52017,\n",
       " 'transvestism': 40833,\n",
       " \"hangin'\": 34702,\n",
       " 'bringing': 2338,\n",
       " 'seamier': 40834,\n",
       " 'wooded': 34703,\n",
       " 'bravora': 52018,\n",
       " 'grueling': 16817,\n",
       " 'wooden': 1636,\n",
       " 'wednesday': 16818,\n",
       " \"'prix\": 52019,\n",
       " 'altagracia': 34704,\n",
       " 'circuitry': 52020,\n",
       " 'crotch': 11585,\n",
       " 'busybody': 57766,\n",
       " \"tart'n'tangy\": 52021,\n",
       " 'burgade': 14129,\n",
       " 'thrace': 52023,\n",
       " \"tom's\": 11038,\n",
       " 'snuggles': 52025,\n",
       " 'francesco': 29114,\n",
       " 'complainers': 52027,\n",
       " 'templarios': 52125,\n",
       " '272': 40835,\n",
       " '273': 52028,\n",
       " 'zaniacs': 52130,\n",
       " '275': 34706,\n",
       " 'consenting': 27631,\n",
       " 'snuggled': 40836,\n",
       " 'inanimate': 15492,\n",
       " 'uality': 52030,\n",
       " 'bronte': 11926,\n",
       " 'errors': 4010,\n",
       " 'dialogs': 3230,\n",
       " \"yomada's\": 52031,\n",
       " \"madman's\": 34707,\n",
       " 'dialoge': 30585,\n",
       " 'usenet': 52033,\n",
       " 'videodrome': 40837,\n",
       " \"kid'\": 26338,\n",
       " 'pawed': 52034,\n",
       " \"'girlfriend'\": 30569,\n",
       " \"'pleasure\": 52035,\n",
       " \"'reloaded'\": 52036,\n",
       " \"kazakos'\": 40839,\n",
       " 'rocque': 52037,\n",
       " 'mailings': 52038,\n",
       " 'brainwashed': 11927,\n",
       " 'mcanally': 16819,\n",
       " \"tom''\": 52039,\n",
       " 'kurupt': 25243,\n",
       " 'affiliated': 21905,\n",
       " 'babaganoosh': 52040,\n",
       " \"noe's\": 40840,\n",
       " 'quart': 40841,\n",
       " 'kids': 359,\n",
       " 'uplifting': 5034,\n",
       " 'controversy': 7093,\n",
       " 'kida': 21906,\n",
       " 'kidd': 23379,\n",
       " \"error'\": 52041,\n",
       " 'neurologist': 52042,\n",
       " 'spotty': 18510,\n",
       " 'cobblers': 30570,\n",
       " 'projection': 9878,\n",
       " 'fastforwarding': 40842,\n",
       " 'sters': 52043,\n",
       " \"eggar's\": 52044,\n",
       " 'etherything': 52045,\n",
       " 'gateshead': 40843,\n",
       " 'airball': 34708,\n",
       " 'unsinkable': 25244,\n",
       " 'stern': 7180,\n",
       " \"cervi's\": 52046,\n",
       " 'dnd': 40844,\n",
       " 'dna': 11586,\n",
       " 'insecurity': 20598,\n",
       " \"'reboot'\": 52047,\n",
       " 'trelkovsky': 11037,\n",
       " 'jaekel': 52048,\n",
       " 'sidebars': 52049,\n",
       " \"sforza's\": 52050,\n",
       " 'distortions': 17633,\n",
       " 'mutinies': 52051,\n",
       " 'sermons': 30602,\n",
       " '7ft': 40846,\n",
       " 'boobage': 52052,\n",
       " \"o'bannon's\": 52053,\n",
       " 'populations': 23380,\n",
       " 'chulak': 52054,\n",
       " 'mesmerize': 27633,\n",
       " 'quinnell': 52055,\n",
       " 'yahoo': 10307,\n",
       " 'meteorologist': 52057,\n",
       " 'beswick': 42577,\n",
       " 'boorman': 15493,\n",
       " 'voicework': 40847,\n",
       " \"ster'\": 52058,\n",
       " 'blustering': 22922,\n",
       " 'hj': 52059,\n",
       " 'intake': 27634,\n",
       " 'morally': 5621,\n",
       " 'jumbling': 40849,\n",
       " 'bowersock': 52060,\n",
       " \"'porky's'\": 52061,\n",
       " 'gershon': 16821,\n",
       " 'ludicrosity': 40850,\n",
       " 'coprophilia': 52062,\n",
       " 'expressively': 40851,\n",
       " \"india's\": 19500,\n",
       " \"post's\": 34710,\n",
       " 'wana': 52063,\n",
       " 'wang': 5283,\n",
       " 'wand': 30571,\n",
       " 'wane': 25245,\n",
       " 'edgeways': 52321,\n",
       " 'titanium': 34711,\n",
       " 'pinta': 40852,\n",
       " 'want': 178,\n",
       " 'pinto': 30572,\n",
       " 'whoopdedoodles': 52065,\n",
       " 'tchaikovsky': 21908,\n",
       " 'travel': 2103,\n",
       " \"'victory'\": 52066,\n",
       " 'copious': 11928,\n",
       " 'gouge': 22433,\n",
       " \"chapters'\": 52067,\n",
       " 'barbra': 6702,\n",
       " 'uselessness': 30573,\n",
       " \"wan'\": 52068,\n",
       " 'assimilated': 27635,\n",
       " 'petiot': 16116,\n",
       " 'most\\x85and': 52069,\n",
       " 'dinosaurs': 3930,\n",
       " 'wrong': 352,\n",
       " 'seda': 52070,\n",
       " 'stollen': 52071,\n",
       " 'sentencing': 34712,\n",
       " 'ouroboros': 40853,\n",
       " 'assimilates': 40854,\n",
       " 'colorfully': 40855,\n",
       " 'glenne': 27636,\n",
       " 'dongen': 52072,\n",
       " 'subplots': 4760,\n",
       " 'kiloton': 52073,\n",
       " 'chandon': 23381,\n",
       " \"effect'\": 34713,\n",
       " 'snugly': 27637,\n",
       " 'kuei': 40856,\n",
       " 'welcomed': 9092,\n",
       " 'dishonor': 30071,\n",
       " 'concurrence': 52075,\n",
       " 'stoicism': 23382,\n",
       " \"guys'\": 14896,\n",
       " \"beroemd'\": 52077,\n",
       " 'butcher': 6703,\n",
       " \"melfi's\": 40857,\n",
       " 'aargh': 30623,\n",
       " 'playhouse': 20599,\n",
       " 'wickedly': 11308,\n",
       " 'fit': 1180,\n",
       " 'labratory': 52078,\n",
       " 'lifeline': 40859,\n",
       " 'screaming': 1927,\n",
       " 'fix': 4287,\n",
       " 'cineliterate': 52079,\n",
       " 'fic': 52080,\n",
       " 'fia': 52081,\n",
       " 'fig': 34714,\n",
       " 'fmvs': 52082,\n",
       " 'fie': 52083,\n",
       " 'reentered': 52084,\n",
       " 'fin': 30574,\n",
       " 'doctresses': 52085,\n",
       " 'fil': 52086,\n",
       " 'zucker': 12606,\n",
       " 'ached': 31931,\n",
       " 'counsil': 52088,\n",
       " 'paterfamilias': 52089,\n",
       " 'songwriter': 13885,\n",
       " 'shivam': 34715,\n",
       " 'hurting': 9654,\n",
       " 'effects': 299,\n",
       " 'slauther': 52090,\n",
       " \"'flame'\": 52091,\n",
       " 'sommerset': 52092,\n",
       " 'interwhined': 52093,\n",
       " 'whacking': 27638,\n",
       " 'bartok': 52094,\n",
       " 'barton': 8775,\n",
       " 'frewer': 21909,\n",
       " \"fi'\": 52095,\n",
       " 'ingrid': 6192,\n",
       " 'stribor': 30575,\n",
       " 'approporiately': 52096,\n",
       " 'wobblyhand': 52097,\n",
       " 'tantalisingly': 52098,\n",
       " 'ankylosaurus': 52099,\n",
       " 'parasites': 17634,\n",
       " 'childen': 52100,\n",
       " \"jenkins'\": 52101,\n",
       " 'metafiction': 52102,\n",
       " 'golem': 17635,\n",
       " 'indiscretion': 40860,\n",
       " \"reeves'\": 23383,\n",
       " \"inamorata's\": 57781,\n",
       " 'brittannica': 52104,\n",
       " 'adapt': 7916,\n",
       " \"russo's\": 30576,\n",
       " 'guitarists': 48246,\n",
       " 'abbott': 10553,\n",
       " 'abbots': 40861,\n",
       " 'lanisha': 17649,\n",
       " 'magickal': 40863,\n",
       " 'mattter': 52105,\n",
       " \"'willy\": 52106,\n",
       " 'pumpkins': 34716,\n",
       " 'stuntpeople': 52107,\n",
       " 'estimate': 30577,\n",
       " 'ugghhh': 40864,\n",
       " 'gameplay': 11309,\n",
       " \"wern't\": 52108,\n",
       " \"n'sync\": 40865,\n",
       " 'sickeningly': 16117,\n",
       " 'chiara': 40866,\n",
       " 'disturbed': 4011,\n",
       " 'portmanteau': 40867,\n",
       " 'ineffectively': 52109,\n",
       " \"duchonvey's\": 82143,\n",
       " \"nasty'\": 37519,\n",
       " 'purpose': 1285,\n",
       " 'lazers': 52112,\n",
       " 'lightened': 28105,\n",
       " 'kaliganj': 52113,\n",
       " 'popularism': 52114,\n",
       " \"damme's\": 18511,\n",
       " 'stylistics': 30578,\n",
       " 'mindgaming': 52115,\n",
       " 'spoilerish': 46449,\n",
       " \"'corny'\": 52117,\n",
       " 'boerner': 34718,\n",
       " 'olds': 6792,\n",
       " 'bakelite': 52118,\n",
       " 'renovated': 27639,\n",
       " 'forrester': 27640,\n",
       " \"lumiere's\": 52119,\n",
       " 'gaskets': 52024,\n",
       " 'needed': 884,\n",
       " 'smight': 34719,\n",
       " 'master': 1297,\n",
       " \"edie's\": 25905,\n",
       " 'seeber': 40868,\n",
       " 'hiya': 52120,\n",
       " 'fuzziness': 52121,\n",
       " 'genesis': 14897,\n",
       " 'rewards': 12607,\n",
       " 'enthrall': 30579,\n",
       " \"'about\": 40869,\n",
       " \"recollection's\": 52122,\n",
       " 'mutilated': 11039,\n",
       " 'fatherlands': 52123,\n",
       " \"fischer's\": 52124,\n",
       " 'positively': 5399,\n",
       " '270': 34705,\n",
       " 'ahmed': 34720,\n",
       " 'zatoichi': 9836,\n",
       " 'bannister': 13886,\n",
       " 'anniversaries': 52127,\n",
       " \"helm's\": 30580,\n",
       " \"'work'\": 52128,\n",
       " 'exclaimed': 34721,\n",
       " \"'unfunny'\": 52129,\n",
       " '274': 52029,\n",
       " 'feeling': 544,\n",
       " \"wanda's\": 52131,\n",
       " 'dolan': 33266,\n",
       " '278': 52133,\n",
       " 'peacoat': 52134,\n",
       " 'brawny': 40870,\n",
       " 'mishra': 40871,\n",
       " 'worlders': 40872,\n",
       " 'protags': 52135,\n",
       " 'skullcap': 52136,\n",
       " 'dastagir': 57596,\n",
       " 'affairs': 5622,\n",
       " 'wholesome': 7799,\n",
       " 'hymen': 52137,\n",
       " 'paramedics': 25246,\n",
       " 'unpersons': 52138,\n",
       " 'heavyarms': 52139,\n",
       " 'affaire': 52140,\n",
       " 'coulisses': 52141,\n",
       " 'hymer': 40873,\n",
       " 'kremlin': 52142,\n",
       " 'shipments': 30581,\n",
       " 'pixilated': 52143,\n",
       " \"'00s\": 30582,\n",
       " 'diminishing': 18512,\n",
       " 'cinematic': 1357,\n",
       " 'resonates': 14898,\n",
       " 'simplify': 40874,\n",
       " \"nature'\": 40875,\n",
       " 'temptresses': 40876,\n",
       " 'reverence': 16822,\n",
       " 'resonated': 19502,\n",
       " 'dailey': 34722,\n",
       " '2\\x85': 52144,\n",
       " 'treize': 27641,\n",
       " 'majo': 52145,\n",
       " 'kiya': 21910,\n",
       " 'woolnough': 52146,\n",
       " 'thanatos': 39797,\n",
       " 'sandoval': 35731,\n",
       " 'dorama': 40879,\n",
       " \"o'shaughnessy\": 52147,\n",
       " 'tech': 4988,\n",
       " 'fugitives': 32018,\n",
       " 'teck': 30583,\n",
       " \"'e'\": 76125,\n",
       " 'doesn’t': 40881,\n",
       " 'purged': 52149,\n",
       " 'saying': 657,\n",
       " \"martians'\": 41095,\n",
       " 'norliss': 23418,\n",
       " 'dickey': 27642,\n",
       " 'dicker': 52152,\n",
       " \"'sependipity\": 52153,\n",
       " 'padded': 8422,\n",
       " 'ordell': 57792,\n",
       " \"sturges'\": 40882,\n",
       " 'independentcritics': 52154,\n",
       " 'tempted': 5745,\n",
       " \"atkinson's\": 34724,\n",
       " 'hounded': 25247,\n",
       " 'apace': 52155,\n",
       " 'clicked': 15494,\n",
       " \"'humor'\": 30584,\n",
       " \"martino's\": 17177,\n",
       " \"'supporting\": 52156,\n",
       " 'warmongering': 52032,\n",
       " \"zemeckis's\": 34725,\n",
       " 'lube': 21911,\n",
       " 'shocky': 52157,\n",
       " 'plate': 7476,\n",
       " 'plata': 40883,\n",
       " 'sturgess': 40884,\n",
       " \"nerds'\": 40885,\n",
       " 'plato': 20600,\n",
       " 'plath': 34726,\n",
       " 'platt': 40886,\n",
       " 'mcnab': 52159,\n",
       " 'clumsiness': 27643,\n",
       " 'altogether': 3899,\n",
       " 'massacring': 42584,\n",
       " 'bicenntinial': 52160,\n",
       " 'skaal': 40887,\n",
       " 'droning': 14360,\n",
       " 'lds': 8776,\n",
       " 'jaguar': 21912,\n",
       " \"cale's\": 34727,\n",
       " 'nicely': 1777,\n",
       " 'mummy': 4588,\n",
       " \"lot's\": 18513,\n",
       " 'patch': 10086,\n",
       " 'kerkhof': 50202,\n",
       " \"leader's\": 52161,\n",
       " \"'movie\": 27644,\n",
       " 'uncomfirmed': 52162,\n",
       " 'heirloom': 40888,\n",
       " 'wrangle': 47360,\n",
       " 'emotion\\x85': 52163,\n",
       " \"'stargate'\": 52164,\n",
       " 'pinoy': 40889,\n",
       " 'conchatta': 40890,\n",
       " 'broeke': 41128,\n",
       " 'advisedly': 40891,\n",
       " \"barker's\": 17636,\n",
       " 'descours': 52166,\n",
       " 'lots': 772,\n",
       " 'lotr': 9259,\n",
       " 'irs': 9879,\n",
       " 'lott': 52167,\n",
       " 'xvi': 40892,\n",
       " 'irk': 34728,\n",
       " 'irl': 52168,\n",
       " 'ira': 6887,\n",
       " 'belzer': 21913,\n",
       " 'irc': 52169,\n",
       " 'ire': 27645,\n",
       " 'requisites': 40893,\n",
       " 'discipline': 7693,\n",
       " 'lyoko': 52961,\n",
       " 'extend': 11310,\n",
       " 'nature': 873,\n",
       " \"'dickie'\": 52170,\n",
       " 'optimist': 40894,\n",
       " 'lapping': 30586,\n",
       " 'superficial': 3900,\n",
       " 'vestment': 52171,\n",
       " 'extent': 2823,\n",
       " 'tendons': 52172,\n",
       " \"heller's\": 52173,\n",
       " 'quagmires': 52174,\n",
       " 'miyako': 52175,\n",
       " 'moocow': 20601,\n",
       " \"coles'\": 52176,\n",
       " 'lookit': 40895,\n",
       " 'ravenously': 52177,\n",
       " 'levitating': 40896,\n",
       " 'perfunctorily': 52178,\n",
       " 'lookin': 30587,\n",
       " \"lot'\": 40898,\n",
       " 'lookie': 52179,\n",
       " 'fearlessly': 34870,\n",
       " 'libyan': 52181,\n",
       " 'fondles': 40899,\n",
       " 'gopher': 35714,\n",
       " 'wearying': 40901,\n",
       " \"nz's\": 52182,\n",
       " 'minuses': 27646,\n",
       " 'puposelessly': 52183,\n",
       " 'shandling': 52184,\n",
       " 'decapitates': 31268,\n",
       " 'humming': 11929,\n",
       " \"'nother\": 40902,\n",
       " 'smackdown': 21914,\n",
       " 'underdone': 30588,\n",
       " 'frf': 40903,\n",
       " 'triviality': 52185,\n",
       " 'fro': 25248,\n",
       " 'bothers': 8777,\n",
       " \"'kensington\": 52186,\n",
       " 'much': 73,\n",
       " 'muco': 34730,\n",
       " 'wiseguy': 22615,\n",
       " \"richie's\": 27648,\n",
       " 'tonino': 40904,\n",
       " 'unleavened': 52187,\n",
       " 'fry': 11587,\n",
       " \"'tv'\": 40905,\n",
       " 'toning': 40906,\n",
       " 'obese': 14361,\n",
       " 'sensationalized': 30589,\n",
       " 'spiv': 40907,\n",
       " 'spit': 6259,\n",
       " 'arkin': 7364,\n",
       " 'charleton': 21915,\n",
       " 'jeon': 16823,\n",
       " 'boardroom': 21916,\n",
       " 'doubts': 4989,\n",
       " 'spin': 3084,\n",
       " 'hepo': 53083,\n",
       " 'wildcat': 27649,\n",
       " 'venoms': 10584,\n",
       " 'misconstrues': 52191,\n",
       " 'mesmerising': 18514,\n",
       " 'misconstrued': 40908,\n",
       " 'rescinds': 52192,\n",
       " 'prostrate': 52193,\n",
       " 'majid': 40909,\n",
       " 'climbed': 16479,\n",
       " 'canoeing': 34731,\n",
       " 'majin': 52195,\n",
       " 'animie': 57804,\n",
       " 'sylke': 40910,\n",
       " 'conditioned': 14899,\n",
       " 'waddell': 40911,\n",
       " '3\\x85': 52196,\n",
       " 'hyperdrive': 41188,\n",
       " 'conditioner': 34732,\n",
       " 'bricklayer': 53153,\n",
       " 'hong': 2576,\n",
       " 'memoriam': 52198,\n",
       " 'inventively': 30592,\n",
       " \"levant's\": 25249,\n",
       " 'portobello': 20638,\n",
       " 'remand': 52200,\n",
       " 'mummified': 19504,\n",
       " 'honk': 27650,\n",
       " 'spews': 19505,\n",
       " 'visitations': 40912,\n",
       " 'mummifies': 52201,\n",
       " 'cavanaugh': 25250,\n",
       " 'zeon': 23385,\n",
       " \"jungle's\": 40913,\n",
       " 'viertel': 34733,\n",
       " 'frenchmen': 27651,\n",
       " 'torpedoes': 52202,\n",
       " 'schlessinger': 52203,\n",
       " 'torpedoed': 34734,\n",
       " 'blister': 69876,\n",
       " 'cinefest': 52204,\n",
       " 'furlough': 34735,\n",
       " 'mainsequence': 52205,\n",
       " 'mentors': 40914,\n",
       " 'academic': 9094,\n",
       " 'stillness': 20602,\n",
       " 'academia': 40915,\n",
       " 'lonelier': 52206,\n",
       " 'nibby': 52207,\n",
       " \"losers'\": 52208,\n",
       " 'cineastes': 40916,\n",
       " 'corporate': 4449,\n",
       " 'massaging': 40917,\n",
       " 'bellow': 30593,\n",
       " 'absurdities': 19506,\n",
       " 'expetations': 53241,\n",
       " 'nyfiken': 40918,\n",
       " 'mehras': 75638,\n",
       " 'lasse': 52209,\n",
       " 'visability': 52210,\n",
       " 'militarily': 33946,\n",
       " \"elder'\": 52211,\n",
       " 'gainsbourg': 19023,\n",
       " 'hah': 20603,\n",
       " 'hai': 13420,\n",
       " 'haj': 34736,\n",
       " 'hak': 25251,\n",
       " 'hal': 4311,\n",
       " 'ham': 4892,\n",
       " 'duffer': 53259,\n",
       " 'haa': 52213,\n",
       " 'had': 66,\n",
       " 'advancement': 11930,\n",
       " 'hag': 16825,\n",
       " \"hand'\": 25252,\n",
       " 'hay': 13421,\n",
       " 'mcnamara': 20604,\n",
       " \"mozart's\": 52214,\n",
       " 'duffel': 30731,\n",
       " 'haq': 30594,\n",
       " 'har': 13887,\n",
       " 'has': 44,\n",
       " 'hat': 2401,\n",
       " 'hav': 40919,\n",
       " 'haw': 30595,\n",
       " 'figtings': 52215,\n",
       " 'elders': 15495,\n",
       " 'underpanted': 52216,\n",
       " 'pninson': 52217,\n",
       " 'unequivocally': 27652,\n",
       " \"barbara's\": 23673,\n",
       " \"bello'\": 52219,\n",
       " 'indicative': 12997,\n",
       " 'yawnfest': 40920,\n",
       " 'hexploitation': 52220,\n",
       " \"loder's\": 52221,\n",
       " 'sleuthing': 27653,\n",
       " \"justin's\": 32622,\n",
       " \"'ball\": 52222,\n",
       " \"'summer\": 52223,\n",
       " \"'demons'\": 34935,\n",
       " \"mormon's\": 52225,\n",
       " \"laughton's\": 34737,\n",
       " 'debell': 52226,\n",
       " 'shipyard': 39724,\n",
       " 'unabashedly': 30597,\n",
       " 'disks': 40401,\n",
       " 'crowd': 2290,\n",
       " 'crowe': 10087,\n",
       " \"vancouver's\": 56434,\n",
       " 'mosques': 34738,\n",
       " 'crown': 6627,\n",
       " 'culpas': 52227,\n",
       " 'crows': 27654,\n",
       " 'surrell': 53344,\n",
       " 'flowless': 52229,\n",
       " 'sheirk': 52230,\n",
       " \"'three\": 40923,\n",
       " \"peterson'\": 52231,\n",
       " 'ooverall': 52232,\n",
       " 'perchance': 40924,\n",
       " 'bottom': 1321,\n",
       " 'chabert': 53363,\n",
       " 'sneha': 52233,\n",
       " 'inhuman': 13888,\n",
       " 'ichii': 52234,\n",
       " 'ursla': 52235,\n",
       " 'completly': 30598,\n",
       " 'moviedom': 40925,\n",
       " 'raddick': 52236,\n",
       " 'brundage': 51995,\n",
       " 'brigades': 40926,\n",
       " 'starring': 1181,\n",
       " \"'goal'\": 52237,\n",
       " 'caskets': 52238,\n",
       " 'willcock': 52239,\n",
       " \"threesome's\": 52240,\n",
       " \"mosque'\": 52241,\n",
       " \"cover's\": 52242,\n",
       " 'spaceships': 17637,\n",
       " 'anomalous': 40927,\n",
       " 'ptsd': 27655,\n",
       " 'shirdan': 52243,\n",
       " 'obscenity': 21962,\n",
       " 'lemmings': 30599,\n",
       " 'duccio': 30600,\n",
       " \"levene's\": 52244,\n",
       " \"'gorby'\": 52245,\n",
       " \"teenager's\": 25255,\n",
       " 'marshall': 5340,\n",
       " 'honeymoon': 9095,\n",
       " 'shoots': 3231,\n",
       " 'despised': 12258,\n",
       " 'okabasho': 52246,\n",
       " 'fabric': 8289,\n",
       " 'cannavale': 18515,\n",
       " 'raped': 3537,\n",
       " \"tutt's\": 52247,\n",
       " 'grasping': 17638,\n",
       " 'despises': 18516,\n",
       " \"thief's\": 40928,\n",
       " 'rapes': 8926,\n",
       " 'raper': 52248,\n",
       " \"eyre'\": 27656,\n",
       " 'walchek': 52249,\n",
       " \"elmo's\": 23386,\n",
       " 'perfumes': 40929,\n",
       " 'spurting': 21918,\n",
       " \"exposition'\\x85\": 52250,\n",
       " 'denoting': 52251,\n",
       " 'thesaurus': 34740,\n",
       " \"shoot'\": 40930,\n",
       " 'bonejack': 49759,\n",
       " 'simpsonian': 52253,\n",
       " 'hebetude': 30601,\n",
       " \"hallow's\": 34741,\n",
       " 'desperation\\x85': 52254,\n",
       " 'incinerator': 34742,\n",
       " 'congratulations': 10308,\n",
       " 'humbled': 52255,\n",
       " \"else's\": 5924,\n",
       " 'trelkovski': 40845,\n",
       " \"rape'\": 52256,\n",
       " \"'chapters'\": 59386,\n",
       " '1600s': 52257,\n",
       " 'martian': 7253,\n",
       " 'nicest': 25256,\n",
       " 'eyred': 52259,\n",
       " 'passenger': 9457,\n",
       " 'disgrace': 6041,\n",
       " 'moderne': 52260,\n",
       " 'barrymore': 5120,\n",
       " 'yankovich': 52261,\n",
       " 'moderns': 40931,\n",
       " 'studliest': 52262,\n",
       " 'bedsheet': 52263,\n",
       " 'decapitation': 14900,\n",
       " 'slurring': 52264,\n",
       " \"'nunsploitation'\": 52265,\n",
       " \"'character'\": 34743,\n",
       " 'cambodia': 9880,\n",
       " 'rebelious': 52266,\n",
       " 'pasadena': 27657,\n",
       " 'crowne': 40932,\n",
       " \"'bedchamber\": 52267,\n",
       " 'conjectural': 52268,\n",
       " 'appologize': 52269,\n",
       " 'halfassing': 52270,\n",
       " 'paycheque': 57816,\n",
       " 'palms': 20606,\n",
       " \"'islands\": 52271,\n",
       " 'hawked': 40933,\n",
       " 'palme': 21919,\n",
       " 'conservatively': 40934,\n",
       " 'larp': 64007,\n",
       " 'palma': 5558,\n",
       " 'smelling': 21920,\n",
       " 'aragorn': 12998,\n",
       " 'hawker': 52272,\n",
       " 'hawkes': 52273,\n",
       " 'explosions': 3975,\n",
       " 'loren': 8059,\n",
       " \"pyle's\": 52274,\n",
       " 'shootout': 6704,\n",
       " \"mike's\": 18517,\n",
       " \"driscoll's\": 52275,\n",
       " 'cogsworth': 40935,\n",
       " \"britian's\": 52276,\n",
       " 'childs': 34744,\n",
       " \"portrait's\": 52277,\n",
       " 'chain': 3626,\n",
       " 'whoever': 2497,\n",
       " 'puttered': 52278,\n",
       " 'childe': 52279,\n",
       " 'maywether': 52280,\n",
       " 'chair': 3036,\n",
       " \"rance's\": 52281,\n",
       " 'machu': 34745,\n",
       " 'ballet': 4517,\n",
       " 'grapples': 34746,\n",
       " 'summerize': 76152,\n",
       " 'freelance': 30603,\n",
       " \"andrea's\": 52283,\n",
       " '\\x91very': 52284,\n",
       " 'coolidge': 45879,\n",
       " 'mache': 18518,\n",
       " 'balled': 52285,\n",
       " 'grappled': 40937,\n",
       " 'macha': 18519,\n",
       " 'underlining': 21921,\n",
       " 'macho': 5623,\n",
       " 'oversight': 19507,\n",
       " 'machi': 25257,\n",
       " 'verbally': 11311,\n",
       " 'tenacious': 21922,\n",
       " 'windshields': 40938,\n",
       " 'paychecks': 18557,\n",
       " 'jerk': 3396,\n",
       " \"good'\": 11931,\n",
       " 'prancer': 34748,\n",
       " 'prances': 21923,\n",
       " 'olympus': 52286,\n",
       " 'lark': 21924,\n",
       " 'embark': 10785,\n",
       " 'gloomy': 7365,\n",
       " 'jehaan': 52287,\n",
       " 'turaqui': 52288,\n",
       " \"child'\": 20607,\n",
       " 'locked': 2894,\n",
       " 'pranced': 52289,\n",
       " 'exact': 2588,\n",
       " 'unattuned': 52290,\n",
       " 'minute': 783,\n",
       " 'skewed': 16118,\n",
       " 'hodgins': 40940,\n",
       " 'skewer': 34749,\n",
       " 'think\\x85': 52291,\n",
       " 'rosenstein': 38765,\n",
       " 'helmit': 52292,\n",
       " 'wrestlemanias': 34750,\n",
       " 'hindered': 16826,\n",
       " \"martha's\": 30604,\n",
       " 'cheree': 52293,\n",
       " \"pluckin'\": 52294,\n",
       " 'ogles': 40941,\n",
       " 'heavyweight': 11932,\n",
       " 'aada': 82190,\n",
       " 'chopping': 11312,\n",
       " 'strongboy': 61534,\n",
       " 'hegemonic': 41342,\n",
       " 'adorns': 40942,\n",
       " 'xxth': 41346,\n",
       " 'nobuhiro': 34751,\n",
       " 'capitães': 52298,\n",
       " 'kavogianni': 52299,\n",
       " 'antwerp': 13422,\n",
       " 'celebrated': 6538,\n",
       " 'roarke': 52300,\n",
       " 'baggins': 40943,\n",
       " 'cheeseburgers': 31270,\n",
       " 'matras': 52301,\n",
       " \"nineties'\": 52302,\n",
       " \"'craig'\": 52303,\n",
       " 'celebrates': 12999,\n",
       " 'unintentionally': 3383,\n",
       " 'drafted': 14362,\n",
       " 'climby': 52304,\n",
       " '303': 52305,\n",
       " 'oldies': 18520,\n",
       " 'climbs': 9096,\n",
       " 'honour': 9655,\n",
       " 'plucking': 34752,\n",
       " '305': 30074,\n",
       " 'address': 5514,\n",
       " 'menjou': 40944,\n",
       " \"'freak'\": 42592,\n",
       " 'dwindling': 19508,\n",
       " 'benson': 9458,\n",
       " 'white’s': 52307,\n",
       " 'shamelessness': 40945,\n",
       " 'impacted': 21925,\n",
       " 'upatz': 52308,\n",
       " 'cusack': 3840,\n",
       " \"flavia's\": 37567,\n",
       " 'effette': 52309,\n",
       " 'influx': 34753,\n",
       " 'boooooooo': 52310,\n",
       " 'dimitrova': 52311,\n",
       " 'houseman': 13423,\n",
       " 'bigas': 25259,\n",
       " 'boylen': 52312,\n",
       " 'phillipenes': 52313,\n",
       " 'fakery': 40946,\n",
       " \"grandpa's\": 27658,\n",
       " 'darnell': 27659,\n",
       " 'undergone': 19509,\n",
       " 'handbags': 52315,\n",
       " 'perished': 21926,\n",
       " 'pooped': 37778,\n",
       " 'vigour': 27660,\n",
       " 'opposed': 3627,\n",
       " 'etude': 52316,\n",
       " \"caine's\": 11799,\n",
       " 'doozers': 52317,\n",
       " 'photojournals': 34754,\n",
       " 'perishes': 52318,\n",
       " 'constrains': 34755,\n",
       " 'migenes': 40948,\n",
       " 'consoled': 30605,\n",
       " 'alastair': 16827,\n",
       " 'wvs': 52319,\n",
       " 'ooooooh': 52320,\n",
       " 'approving': 34756,\n",
       " 'consoles': 40949,\n",
       " 'disparagement': 52064,\n",
       " 'futureistic': 52322,\n",
       " 'rebounding': 52323,\n",
       " \"'date\": 52324,\n",
       " 'gregoire': 52325,\n",
       " 'rutherford': 21927,\n",
       " 'americanised': 34757,\n",
       " 'novikov': 82196,\n",
       " 'following': 1042,\n",
       " 'munroe': 34758,\n",
       " \"morita'\": 52326,\n",
       " 'christenssen': 52327,\n",
       " 'oatmeal': 23106,\n",
       " 'fossey': 25260,\n",
       " 'livered': 40950,\n",
       " 'listens': 13000,\n",
       " \"'marci\": 76164,\n",
       " \"otis's\": 52330,\n",
       " 'thanking': 23387,\n",
       " 'maude': 16019,\n",
       " 'extensions': 34759,\n",
       " 'ameteurish': 52332,\n",
       " \"commender's\": 52333,\n",
       " 'agricultural': 27661,\n",
       " 'convincingly': 4518,\n",
       " 'fueled': 17639,\n",
       " 'mahattan': 54014,\n",
       " \"paris's\": 40952,\n",
       " 'vulkan': 52336,\n",
       " 'stapes': 52337,\n",
       " 'odysessy': 52338,\n",
       " 'harmon': 12259,\n",
       " 'surfing': 4252,\n",
       " 'halloran': 23494,\n",
       " 'unbelieveably': 49580,\n",
       " \"'offed'\": 52339,\n",
       " 'quadrant': 30607,\n",
       " 'inhabiting': 19510,\n",
       " 'nebbish': 34760,\n",
       " 'forebears': 40953,\n",
       " 'skirmish': 34761,\n",
       " 'ocassionally': 52340,\n",
       " \"'resist\": 52341,\n",
       " 'impactful': 21928,\n",
       " 'spicier': 52342,\n",
       " 'touristy': 40954,\n",
       " \"'football'\": 52343,\n",
       " 'webpage': 40955,\n",
       " 'exurbia': 52345,\n",
       " 'jucier': 52346,\n",
       " 'professors': 14901,\n",
       " 'structuring': 34762,\n",
       " 'jig': 30608,\n",
       " 'overlord': 40956,\n",
       " 'disconnect': 25261,\n",
       " 'sniffle': 82201,\n",
       " 'slimeball': 40957,\n",
       " 'jia': 40958,\n",
       " 'milked': 16828,\n",
       " 'banjoes': 40959,\n",
       " 'jim': 1237,\n",
       " 'workforces': 52348,\n",
       " 'jip': 52349,\n",
       " 'rotweiller': 52350,\n",
       " 'mundaneness': 34763,\n",
       " \"'ninja'\": 52351,\n",
       " \"dead'\": 11040,\n",
       " \"cipriani's\": 40960,\n",
       " 'modestly': 20608,\n",
       " \"professor'\": 52352,\n",
       " 'shacked': 40961,\n",
       " 'bashful': 34764,\n",
       " 'sorter': 23388,\n",
       " 'overpowering': 16120,\n",
       " 'workmanlike': 18521,\n",
       " 'henpecked': 27662,\n",
       " 'sorted': 18522,\n",
       " \"jōb's\": 52354,\n",
       " \"'always\": 52355,\n",
       " \"'baptists\": 34765,\n",
       " 'dreamcatchers': 52356,\n",
       " \"'silence'\": 52357,\n",
       " 'hickory': 21929,\n",
       " 'fun\\x97yet': 52358,\n",
       " 'breakumentary': 52359,\n",
       " 'didn': 15496,\n",
       " 'didi': 52360,\n",
       " 'pealing': 52361,\n",
       " 'dispite': 40962,\n",
       " \"italy's\": 25262,\n",
       " 'instability': 21930,\n",
       " 'quarter': 6539,\n",
       " 'quartet': 12608,\n",
       " 'padmé': 52362,\n",
       " \"'bleedmedry\": 52363,\n",
       " 'pahalniuk': 52364,\n",
       " 'honduras': 52365,\n",
       " 'bursting': 10786,\n",
       " \"pablo's\": 41465,\n",
       " 'irremediably': 52367,\n",
       " 'presages': 40963,\n",
       " 'bowlegged': 57832,\n",
       " 'dalip': 65183,\n",
       " 'entering': 6260,\n",
       " 'newsradio': 76172,\n",
       " 'presaged': 54150,\n",
       " \"giallo's\": 27663,\n",
       " 'bouyant': 40964,\n",
       " 'amerterish': 52368,\n",
       " 'rajni': 18523,\n",
       " 'leeves': 30610,\n",
       " 'macauley': 34767,\n",
       " 'seriously': 612,\n",
       " 'sugercoma': 52369,\n",
       " 'grimstead': 52370,\n",
       " \"'fairy'\": 52371,\n",
       " 'zenda': 30611,\n",
       " \"'twins'\": 52372,\n",
       " 'realisation': 17640,\n",
       " 'highsmith': 27664,\n",
       " 'raunchy': 7817,\n",
       " 'incentives': 40965,\n",
       " 'flatson': 52374,\n",
       " 'snooker': 35097,\n",
       " 'crazies': 16829,\n",
       " 'crazier': 14902,\n",
       " 'grandma': 7094,\n",
       " 'napunsaktha': 52375,\n",
       " 'workmanship': 30612,\n",
       " 'reisner': 52376,\n",
       " \"sanford's\": 61306,\n",
       " '\\x91doña': 52377,\n",
       " 'modest': 6108,\n",
       " \"everything's\": 19153,\n",
       " 'hamer': 40966,\n",
       " \"couldn't'\": 52379,\n",
       " 'quibble': 13001,\n",
       " 'socking': 52380,\n",
       " 'tingler': 21931,\n",
       " 'gutman': 52381,\n",
       " 'lachlan': 40967,\n",
       " 'tableaus': 52382,\n",
       " 'headbanger': 52383,\n",
       " 'spoken': 2847,\n",
       " 'cerebrally': 34768,\n",
       " \"'road\": 23490,\n",
       " 'tableaux': 21932,\n",
       " \"proust's\": 40968,\n",
       " 'periodical': 40969,\n",
       " \"shoveller's\": 52385,\n",
       " 'tamara': 25263,\n",
       " 'affords': 17641,\n",
       " 'concert': 3249,\n",
       " \"yara's\": 87955,\n",
       " 'someome': 52386,\n",
       " 'lingering': 8424,\n",
       " \"abraham's\": 41511,\n",
       " 'beesley': 34769,\n",
       " 'cherbourg': 34770,\n",
       " 'kagan': 28624,\n",
       " 'snatch': 9097,\n",
       " \"miyazaki's\": 9260,\n",
       " 'absorbs': 25264,\n",
       " \"koltai's\": 40970,\n",
       " 'tingled': 64027,\n",
       " 'crossroads': 19511,\n",
       " 'rehab': 16121,\n",
       " 'falworth': 52389,\n",
       " 'sequals': 52390,\n",
       " ...}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dictionary))\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "485b84d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=[]\n",
    "for no in X_train[0]:\n",
    "    for (key,value) in dictionary.items():\n",
    "        if no==value:\n",
    "            text.append(key)\n",
    "\n",
    "\n",
    "\" \".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c89fcd8",
   "metadata": {},
   "source": [
    "Now, let us see what its sentiment is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3fbe5a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "print(\"positive\" if y_train[0]==1 else \"negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fe5c92",
   "metadata": {},
   "source": [
    "Much better version is given in the link below :\n",
    "https://builtin.com/data-science/how-build-neural-networks-keras\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d4e2b8",
   "metadata": {},
   "source": [
    "Now, lets define a function to handle all this, and package it nicely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59db7e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "# Function giving us the decoded text from the word index we have given\n",
    "####################################################################\n",
    "\n",
    "def text_decoder_back(n_list,dictionary):\n",
    "    text=[]\n",
    "    for no in n_list:\n",
    "        for (key,value) in dictionary.items():\n",
    "            if no==value:\n",
    "                text.append(key)\n",
    "    text=\" \".join(text)\n",
    "    return text\n",
    "#####################################################################\n",
    "# End of Fucntion\n",
    "###################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d486ada4",
   "metadata": {},
   "source": [
    "**Approach**\n",
    "First we will try to run using simple Neural Network that doesn't do the embedding and simply takes in the vector supplied and tries to identify the patterns of sentiment. Then we will go with Sequential analysis of the data nd march ahead from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c70e42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbg(n):\n",
    "    print(\"--------------Debug Statement ---------------\")\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fa863be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Debug Statement ---------------\n",
      "1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-304e496e9d90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m \u001b[0mmy_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTf_language_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-130-304e496e9d90>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_Data, memory, *args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_built\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-130-304e496e9d90>\u001b[0m in \u001b[0;36mmodel_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mtemp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTf_language_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_built\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m       \u001b[0mother_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msupported_kwargs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0minject_functional_model_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m       \u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m       \u001b[1;31m# In case there is any multiple inheritance here, we need to call the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_tensor_usage_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nested_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m     \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36massert_no_legacy_layers\u001b[1;34m(layers)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m   \u001b[1;31m# isinstance check for tf.layers.Layer introduces a circular dependency.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m   \u001b[0mlegacy_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_is_legacy_layer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlegacy_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[0mlayer_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'  '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlegacy_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not iterable"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "class Tf_language_model(tensorflow.keras.Model):\n",
    "    embed_size=128 # To Change\n",
    "    max_features=5000 #To change\n",
    "    \n",
    "    #####################################################################\n",
    "    #####################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #####################################################################\n",
    "    #####################################################################\n",
    "    import tensorflow\n",
    "    import tensorflow as tf\n",
    "    import tensorflow.keras as k\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "    from tensorflow.keras.layers import Convolution1D\n",
    "    from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "    \n",
    "    ##################################################################### \n",
    "    ##################################################################### \n",
    "    def __init__(self,input_Data,memory=True,*args,**kwargs):\n",
    "        self.memory_model=memory\n",
    "        dbg(1)\n",
    "        self.model_built=False\n",
    "        self.X_train=input_Data\n",
    "        self.model_init()\n",
    "        self.inputs=tensorflow.keras.Input(shape=())\n",
    "        \n",
    "    def model_init(self):\n",
    "        from tensorflow.keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\n",
    "        from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "        from tensorflow.keras.models import Model, Sequential\n",
    "        if not self.model_built:\n",
    "            inputs=Input(shape=(self.X_train.shape[0]))\n",
    "            x=Embedding(Tf_language_model.max_features, Tf_language_model.embed_size)(inputs)\n",
    "            if self.memory_model==True:\n",
    "                #Bidirectional model is to be added here.\n",
    "                x=Bidirectional(LSTM(32, return_sequences = True))(x)\n",
    "            else:\n",
    "                x=Dense(Tf_language_model.embed_size/2)(x)\n",
    "                x=Dropout(0.2)(x)\n",
    "            temp=Tf_language_model.embed_size/2\n",
    "            while temp>2:\n",
    "                x=Dense(temp)(x)\n",
    "                x=Dropout(0.2)(x)\n",
    "                temp=int(temp/2)\n",
    "            output=Dense(1)(x)\n",
    "            super(Tf_language_model,self).__init__()\n",
    "            self.inputs=inputs\n",
    "            self.ouputs=output\n",
    "            self.compile()\n",
    "            self.model_built=True\n",
    "            print(self.summary())\n",
    "        else:\n",
    "            print(\"Model Already Built\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "my_model=Tf_language_model(X_train,memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b784b6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.model_built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893f107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "705703fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=k.Input(shape=(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c7f23238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y=Dense(20)\n",
    "for i in range(20,1,4):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8bc16de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "10\n",
      "5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "y=k.layers.Dense(60)(inputs)\n",
    "i=20\n",
    "while i>1:\n",
    "    print(i)\n",
    "    y=k.layers.Dense(i)(y)\n",
    "    i=int(i/2)\n",
    "y=k.layers.Dense(1)(y)\n",
    "\n",
    "mod=k.Model(inputs=inputs,outputs=y)\n",
    "mod.compile()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2af8b9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_23')>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bda68000",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build() missing 1 required positional argument: 'input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-3cf776e8a57f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmod2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmod2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmod2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: build() missing 1 required positional argument: 'input_shape'"
     ]
    }
   ],
   "source": [
    "mod2=k.Model()\n",
    "mod2.inputs=inputs\n",
    "mod2.outputs=y\n",
    "mod2.build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "65449fde",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-be99d6917dee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmod2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2475\u001b[0m     \"\"\"\n\u001b[0;32m   2476\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2477\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   2478\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "mod2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd77b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
