{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "713915d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "#from sklearnex import patch_sklearn\n",
    "#patch_sklearn()\n",
    "import sklearn\n",
    "import os\n",
    "import numba\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e795de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad079191",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb703e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_folder=str(\"D:\\\\Work_folders\\\\datasets\\\\NLP-Project2\\\\Data - Sarcasm Detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b4d5b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_json(project_folder+\"\\\\\"+\"Sarcasm_Headlines_Dataset.json\",lines=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bb9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_sarcastic\"].to_csv(\"y_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12feda8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"length\"]=df[\"headline\"].str.len()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b30126c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  length  \n",
       "0  former versace store clerk sues over secret 'b...             0      78  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0      84  \n",
       "2  mom starting to fear son's web series closest ...             1      79  \n",
       "3  boehner just wants wife to listen, not come up...             1      84  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0      64  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1dcd7b",
   "metadata": {},
   "source": [
    "Looks like the data here is listed in three columns and the sarcastic or not decision is quoted in binary - this needs to be checked. \n",
    "\n",
    "Before that we will add a new column that will see how many characters are there in each headline. Also we have to notice that article_link is given here. But, we can go to that article and extract entire text corpus and check out if works out or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b0800b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26709 entries, 0 to 26708\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   article_link  26709 non-null  object\n",
      " 1   headline      26709 non-null  object\n",
      " 2   is_sarcastic  26709 non-null  int64 \n",
      " 3   length        26709 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 834.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67bf68cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_link    False\n",
       "headline        False\n",
       "is_sarcastic    False\n",
       "length          False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3893d60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26709.000000\n",
       "mean        60.910592\n",
       "std         19.184470\n",
       "min          7.000000\n",
       "25%         48.000000\n",
       "50%         61.000000\n",
       "75%         73.000000\n",
       "max        254.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"length\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "941c13f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='length'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df[\"length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "789de974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='length', ylabel='Density'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df[\"length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba4df9",
   "metadata": {},
   "source": [
    "We can't simply correlate the length of the title with that of the sarcastic nature of it or not. I am not subject expert, but I am not considering it as a possibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c560b",
   "metadata": {},
   "source": [
    "We can't eliminate something just because the title is too little. It does depend on context, especially the content of the article will, probably, decide whether the title qualifies to be sarcastic. But, for a machine to be something like that, it pushes the project into some real flux here. It is just a heading, it is supposed to be small for any news paper. On the other hand, we have to be suspect of extra long headlines. It needs some examinations. That means, we have to perhaps chop-off the extra length that we are going to have in our text corpus on the Quartile3. Either abandon those entries altogether, which I think is good idea given how big the corpus is. But we can simply restrict the amount of text that is allowed in that columns and chop off something towards the end or the front. We will do further analysis and see what we can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b148e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([20551,  9973, 11354, 12208, 22596, 14224, 19767,  6919,  8641,\n",
       "             4988,\n",
       "            ...\n",
       "            21262, 24798, 15944, 23473,  7837, 11220, 21783, 15247, 17306,\n",
       "            19868],\n",
       "           dtype='int64', length=26709)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_index=df[\"length\"].sort_values().index\n",
    "check_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac58646c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20551                                              bye bye\n",
       "9973                                              top cute\n",
       "11354                                             déjà vu?\n",
       "12208                                             dip good\n",
       "22596                                             ant born\n",
       "                               ...                        \n",
       "15944    with big names like the cure and grimes shinin...\n",
       "23473    something to vote for on november 8, 2016:    ...\n",
       "7837     roy moore on pedophilia accusers: 'these women...\n",
       "11220    mia farrow: 'it's possible my son was fathered...\n",
       "21783    occasionally you realize someone you thought w...\n",
       "Name: headline, Length: 26706, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"headline\"].loc[check_index[:-3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d006a2",
   "metadata": {},
   "source": [
    "Let us check the last three samples from the data set and see what they are about and do they convey some kind of sarcasm or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79391615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the Headline 254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'maya angelou, poet, author, civil rights activist, and—holy cow—tony award–nominated actress, college professor, magazine editor, streetcar conductor—really? streetcar conductor? wow—calypso singer, nightclub performer, and foreign journalist, dead at 86'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"length of the Headline\",len(df[\"headline\"].loc[check_index[-1]]))\n",
    "df[\"headline\"].loc[check_index[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a00d717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the Headline 237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'elmore leonard, modern prose master, noted for his terse prose style and for writing about things perfectly and succinctly with a remarkable economy of words, unfortunately and sadly expired this gloomy tuesday at the age of 87 years old'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"length of the Headline\",len(df[\"headline\"].loc[check_index[-3]]))\n",
    "df[\"headline\"].loc[check_index[-3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc73e8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the Headline 190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"roy moore on pedophilia accusers: 'these women are only discrediting me now because shifting sociocultural norms have created an environment in which assault allegations are taken seriously'\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"length of the Headline\",len(df[\"headline\"].loc[check_index[-6]]))\n",
    "df[\"headline\"].loc[check_index[-6]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b4df401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the Headline 145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'multi-institutional collaborative clinical trial to examine health benefits of integrative lifestyle practices at the chopra center for wellbeing'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"length of the Headline\",len(df[\"headline\"].loc[check_index[-10]]))\n",
    "df[\"headline\"].loc[check_index[-10]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a32d0a",
   "metadata": {},
   "source": [
    "This doesn't make sense. It doesn't look like it is from one particular article at all. Let us check three more samples before we take a decision on what to do with these things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f000f145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
       "       \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\",\n",
       "       \"mom starting to fear son's web series closest thing she will have to grandchild\",\n",
       "       ..., 'reparations and obama',\n",
       "       'israeli ban targeting boycott supporters raises alarm abroad',\n",
       "       'gourmet gifts for the foodie 2014'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"headline\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec219010",
   "metadata": {},
   "source": [
    "Let us log into one of those and try to get the pure text format of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e424561",
   "metadata": {},
   "source": [
    "https://www.kite.com/python/answers/how-to-extract-text-from-an-html-file-in-python\n",
    "\n",
    "The above is where I got my html text extractor code from. Please give credit where it is due."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f618c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Function used to import data from the given link\n",
    "##############################################################\n",
    "\n",
    "def html_link_extractor(url_given):\n",
    "    from urllib.request import urlopen\n",
    "    from bs4 import BeautifulSoup\n",
    "    url=url_given\n",
    "    #print(url)\n",
    "    html_link=urlopen(url).read()\n",
    "    soup=BeautifulSoup(html_link)\n",
    "    for script in soup([\"script\",\"style\"]):\n",
    "        script.decompose()\n",
    "    strips=list(soup.stripped_strings)\n",
    "    #print(strips)\n",
    "    return strips\n",
    "    \n",
    "##############################################################\n",
    "# End of Function\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c497f319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.theonion.com/maya-angelou-poet-author-civil-rights-activist-and-1819591737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Maya Angelou, Poet, Author, Civil Rights Activist, And—Holy Cow—Tony Award–Nominated Actress, College Professor, Magazine Editor, Streetcar Conductor—Really? Streetcar Conductor? Wow—Calypso Singer, Nightclub Performer, And Foreign Journalist, Dead At 86',\n",
       " 'The Onion',\n",
       " 'The A.V. Club',\n",
       " 'Deadspin',\n",
       " 'Gizmodo',\n",
       " 'Jalopnik',\n",
       " 'Jezebel',\n",
       " 'Kotaku',\n",
       " 'Lifehacker',\n",
       " 'The Root',\n",
       " 'The Takeout',\n",
       " 'The Inventory',\n",
       " \"America's Finest News Source.\",\n",
       " 'Shop',\n",
       " 'Subscribe',\n",
       " 'Home',\n",
       " 'Latest',\n",
       " 'News',\n",
       " 'Local',\n",
       " 'Entertainment',\n",
       " 'Politics',\n",
       " 'Sports',\n",
       " 'Opinion',\n",
       " 'OGN',\n",
       " \"America's Finest News Source.\",\n",
       " 'Home',\n",
       " 'Latest',\n",
       " 'News',\n",
       " 'Local',\n",
       " 'Entertainment',\n",
       " 'Politics',\n",
       " 'Sports',\n",
       " 'Opinion',\n",
       " 'OGN',\n",
       " 'News In Photos',\n",
       " 'Maya Angelou, Poet, Author, Civil Rights Activist, And—Holy Cow—Tony Award–Nominated Actress, College Professor, Magazine Editor, Streetcar Conductor—Really? Streetcar Conductor? Wow—Calypso Singer, Nightclub Performer, And Foreign Journalist, Dead At 86',\n",
       " '5/28/14 12:10PM',\n",
       " 'Breaking News',\n",
       " 'News In Photos']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df[\"article_link\"].loc[check_index[-1]])\n",
    "html_link_extractor(df[\"article_link\"].loc[check_index[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28757d20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.theonion.com/elmore-leonard-modern-prose-master-noted-for-his-ters-1819575450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Elmore Leonard, Modern Prose Master, Noted For His Terse Prose Style And For Writing About Things Perfectly And Succinctly With A Remarkable Economy Of Words, Unfortunately And Sadly Expired This Gloomy Tuesday At The Age Of 87 Years Old',\n",
       " 'The Onion',\n",
       " 'The A.V. Club',\n",
       " 'Deadspin',\n",
       " 'Gizmodo',\n",
       " 'Jalopnik',\n",
       " 'Jezebel',\n",
       " 'Kotaku',\n",
       " 'Lifehacker',\n",
       " 'The Root',\n",
       " 'The Takeout',\n",
       " 'The Inventory',\n",
       " \"America's Finest News Source.\",\n",
       " 'Shop',\n",
       " 'Subscribe',\n",
       " 'Home',\n",
       " 'Latest',\n",
       " 'News',\n",
       " 'Local',\n",
       " 'Entertainment',\n",
       " 'Politics',\n",
       " 'Sports',\n",
       " 'Opinion',\n",
       " 'OGN',\n",
       " \"America's Finest News Source.\",\n",
       " 'Home',\n",
       " 'Latest',\n",
       " 'News',\n",
       " 'Local',\n",
       " 'Entertainment',\n",
       " 'Politics',\n",
       " 'Sports',\n",
       " 'Opinion',\n",
       " 'OGN',\n",
       " 'News In Brief',\n",
       " 'Elmore Leonard, Modern Prose Master, Noted For His Terse Prose Style And For Writing About Things Perfectly And Succinctly With A Remarkable Economy Of Words, Unfortunately And Sadly Expired This Gloomy Tuesday At The Age Of 87 Years Old',\n",
       " '8/20/13 2:21PM',\n",
       " 'PROLOGUE',\n",
       " 'It was 10 a.m. when this reporter—stubbly, lean, and careworn—leaned in his chair, scanning the news for topics of interest, and chanced upon the demise of a very great writer. Gripped suddenly by the inspiration to write, he composed, carefully and with no small degree of consideration, the story you are about to read.',\n",
       " 'Advertisement',\n",
       " 'DETROIT—Earlier this hot and humid day, slim, craggy-faced author Elmore Leonard, the prolific novelist who was known for his terse prose style, as well as for advocating a method of writing that dispensed with unnecessary descriptive detail in favor of succinctness—arguing that needlessly flowery and detailed sentences, for instance, detracted from a work of fiction’s momentum and overall narrative impact—died at 87 years of age. “Elmore passed away this morning at 7:15 a.m. surrounded by his loving family,” a source close to Leonard solemnly intoned in a brief statement this gray and muggy morning after the always bespectacled author, who wrote dozens of popular novels and screenplays from his beloved home in Detroit, the once-bustling city of American industrial power now crumbling under a near half-century of urban decay, suddenly died due to complications from stroke! “Yah, the stroke what he had dere was bad, but up ’til the end Elmore really gave ’er tarpaper, eh? Youse guys, 87 years old and still gon’ Shopko fer bodaydas. Holy wah!” Leonard, who joyfully married the pretty and petite Beverly Cline on a lovely day in 1947, is survived by five children, 12 grandchildren, and countless fans who seek to emulate his perfectly worded and concise, or perhaps the word is curt, or rather laconic, fiction, which was never better than in those narrative situations where tension is at a fever pitch, one character boldly utters something provocative to another, and all hell breaks loose.',\n",
       " 'Breaking News',\n",
       " 'News In Brief']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df[\"article_link\"].loc[check_index[-3]])\n",
    "html_link_extractor(df[\"article_link\"].loc[check_index[-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55c973b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://politics.theonion.com/roy-moore-on-pedophilia-accusers-these-women-are-only-1820405898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Roy Moore On Pedophilia Accusers: ‘These Women Are Only Discrediting Me Now Because Shifting Sociocultural Norms Have Created An Environment In Which Assault Allegations Are Taken Seriously’',\n",
       " 'The Onion',\n",
       " 'The A.V. Club',\n",
       " 'Deadspin',\n",
       " 'Gizmodo',\n",
       " 'Jalopnik',\n",
       " 'Jezebel',\n",
       " 'Kotaku',\n",
       " 'Lifehacker',\n",
       " 'The Root',\n",
       " 'The Takeout',\n",
       " 'The Inventory',\n",
       " \"America's Finest News Source.\",\n",
       " 'Shop',\n",
       " 'Subscribe',\n",
       " 'Home',\n",
       " 'Latest',\n",
       " 'News',\n",
       " 'Local',\n",
       " 'Entertainment',\n",
       " 'Politics',\n",
       " 'Sports',\n",
       " 'Opinion',\n",
       " 'OGN',\n",
       " \"America's Finest News Source.\",\n",
       " 'Home',\n",
       " 'Latest',\n",
       " 'News',\n",
       " 'Local',\n",
       " 'Entertainment',\n",
       " 'Politics',\n",
       " 'Sports',\n",
       " 'Opinion',\n",
       " 'OGN',\n",
       " 'Politics',\n",
       " 'Roy Moore On Pedophilia Accusers: ‘These Women Are Only Discrediting Me Now Because Shifting Sociocultural Norms Have Created An Environment In Which Assault Allegations Are Taken Seriously’',\n",
       " '11/13/17 2:23PM',\n",
       " 'MONTGOMERY, AL—Waving off the current allegations against him as vicious attempts to sabotage his election bid, Alabama Senate candidate Roy Moore told reporters Monday that the women accusing him of pedophilia were only doing so now because “shifting sociocultural norms have created an environment in which assault allegations are taken seriously.” “These women have had 30 years to come forward, and the one and only reason they’re speaking out now is because they suddenly have less fear that their lives will be utterly destroyed,” said Moore, adding that the women accusing him of sexually pursuing them as teenagers were just several of many “jumping on the sexual assault bandwagon these days” in light of meaningful systemic change and the fact that society would no longer immediately discredit them. “My accusers are nothing but slandering opportunists taking advantage of the deteriorating influence of the patriarchy that has traditionally silenced any woman who makes such claims. If the American public at large had not finally begun truly hearing victims and decided that enough was enough, I guarantee that these women would never have had the audacity to accuse me of such heinous crimes.” Moore went on to say that he would nevertheless continue his run for the Senate despite the charges against him because while the norms had shifted, they had not shifted nearly as much in Alabama.',\n",
       " 'Politics']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df[\"article_link\"].loc[check_index[-6]])\n",
    "html_link_extractor(df[\"article_link\"].loc[check_index[-6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a81f04a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.theonion.com/top-cute-1819586814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Top Cute',\n",
       " 'The Onion',\n",
       " 'The A.V. Club',\n",
       " 'Deadspin',\n",
       " 'Gizmodo',\n",
       " 'Jalopnik',\n",
       " 'Jezebel',\n",
       " 'Kotaku',\n",
       " 'Lifehacker',\n",
       " 'The Root',\n",
       " 'The Takeout',\n",
       " 'The Inventory',\n",
       " \"America's Finest News Source.\",\n",
       " 'Shop',\n",
       " 'Subscribe',\n",
       " 'Home',\n",
       " 'Latest',\n",
       " 'News',\n",
       " 'Local',\n",
       " 'Entertainment',\n",
       " 'Politics',\n",
       " 'Sports',\n",
       " 'Opinion',\n",
       " 'OGN',\n",
       " \"America's Finest News Source.\",\n",
       " 'Home',\n",
       " 'Latest',\n",
       " 'News',\n",
       " 'Local',\n",
       " 'Entertainment',\n",
       " 'Politics',\n",
       " 'Sports',\n",
       " 'Opinion',\n",
       " 'OGN',\n",
       " 'News In Photos',\n",
       " 'Top Cute',\n",
       " '5/17/00 3:00PM',\n",
       " 'Breaking News',\n",
       " 'News In Photos']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df[\"article_link\"].loc[check_index[1]])\n",
    "html_link_extractor(df[\"article_link\"].loc[check_index[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9869cb37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(df[\"article_link\"].loc[check_index[2]])\n",
    "#html_link_extractor(df[\"article_link\"].loc[check_index[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bf92e9",
   "metadata": {},
   "source": [
    "**Note** :\n",
    "After examining a few sample contents, it looks incredibly tempting to import a lot of these text and simply append them to our dataframe or atleast dump into a temporary file. I have made a few attempts, which I append at the end of the entire section. It was too many articles and links. It looks more like webscraping. So, I let it rest and work with just the headlines. That means, we are obviously going to misrepresent or not going to properly keep our classification properly. It is going to be riddled with errors. As stated, I consider that outside of the scope of problem statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec90bcc",
   "metadata": {},
   "source": [
    "**Proposed Plan**\n",
    "1. Take the corpus of Texts, do some data cleaning with respect to it, and convert them to tokens.\n",
    "2. Then we will measure the no of words in each text column, considering each entry in the \"title\" column to be a document in itself and the entire column to consisting of a corpus.\n",
    "3. Then we will create a set of words and try to check if every word in the vocabulary we have created is actually inside the dictionary of Glove word vectors given to us along with the problem sets.\n",
    "4. If it doesn't, it necessitates for us to re-construct entire word vector again. It will become extremely difficult. But we will do it by retraining our Glove vector embedding by retraining the Glove. Depending upon the word length and probabilities, we will decide how many dimensions are going to be useful. Of course, we have to eliminate stop words or something, but we will see how we it goes.\n",
    "5. If we do have it such that our vocabulary of the words is not in the original corpus we will generate the embedding layers with the text, as given clearly in the Keras documentations as given below.\n",
    "\n",
    "https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
    "\n",
    "6. We will design layers such that we will include a Bidirectional LSTM along with the embeddings done and will check out for any further modifications. (Finish the objectives later on)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e99f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Function used to prepare file objects for handling and flexibility\n",
    "##############################################################\n",
    "def loading_preparation(project_folder):\n",
    "    file_objects=[]\n",
    "    for each in os.listdir(project_folder):\n",
    "        if \".txt\" in each:\n",
    "            print(\"Imported Files :\",each)\n",
    "            path=os.fspath(project_folder)+\"\\\\\"+each\n",
    "            #file_objects.append(open(path))\n",
    "            file_objects.append(path)\n",
    "    return file_objects\n",
    "##############################################################\n",
    "# End of Function\n",
    "##############################################################\n",
    "\n",
    "##############################################################\n",
    "# Function used to prepare dataframes from the text corpus we have\n",
    "##############################################################\n",
    "@numba.jit\n",
    "def prepare_df(file_path):\n",
    "    data=pd.read_table(file_path,header=None,sep=\"\\n\\r\",lineterminator=\"\\n\")[0]\n",
    "    data=data.apply(str.split)\n",
    "    tf={}\n",
    "    for item in data:\n",
    "        tf.update({item[0] : item[1:]})\n",
    "        #print(item)\n",
    "    return pd.DataFrame(tf).T\n",
    "\n",
    "##############################################################\n",
    "# End of Function\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df610809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Files : glove.6B.100d.txt\n",
      "Imported Files : glove.6B.200d.txt\n",
      "Imported Files : glove.6B.300d.txt\n",
      "Imported Files : glove.6B.50d.txt\n"
     ]
    }
   ],
   "source": [
    "data=prepare_df(loading_preparation(project_folder)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67900e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.038194</td>\n",
       "      <td>-0.24487</td>\n",
       "      <td>0.72812</td>\n",
       "      <td>-0.39961</td>\n",
       "      <td>0.083172</td>\n",
       "      <td>0.043953</td>\n",
       "      <td>-0.39141</td>\n",
       "      <td>0.3344</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>0.087459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016215</td>\n",
       "      <td>-0.017099</td>\n",
       "      <td>-0.38984</td>\n",
       "      <td>0.87424</td>\n",
       "      <td>-0.72569</td>\n",
       "      <td>-0.51058</td>\n",
       "      <td>-0.52028</td>\n",
       "      <td>-0.1459</td>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.27062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.10767</td>\n",
       "      <td>0.11053</td>\n",
       "      <td>0.59812</td>\n",
       "      <td>-0.54361</td>\n",
       "      <td>0.67396</td>\n",
       "      <td>0.10663</td>\n",
       "      <td>0.038867</td>\n",
       "      <td>0.35481</td>\n",
       "      <td>0.06351</td>\n",
       "      <td>-0.094189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.34951</td>\n",
       "      <td>-0.7226</td>\n",
       "      <td>0.37549</td>\n",
       "      <td>0.4441</td>\n",
       "      <td>-0.99059</td>\n",
       "      <td>0.61214</td>\n",
       "      <td>-0.35111</td>\n",
       "      <td>-0.83155</td>\n",
       "      <td>0.45293</td>\n",
       "      <td>0.082577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>-0.33979</td>\n",
       "      <td>0.20941</td>\n",
       "      <td>0.46348</td>\n",
       "      <td>-0.64792</td>\n",
       "      <td>-0.38377</td>\n",
       "      <td>0.038034</td>\n",
       "      <td>0.17127</td>\n",
       "      <td>0.15978</td>\n",
       "      <td>0.46619</td>\n",
       "      <td>-0.019169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063351</td>\n",
       "      <td>-0.67412</td>\n",
       "      <td>-0.068895</td>\n",
       "      <td>0.53604</td>\n",
       "      <td>-0.87773</td>\n",
       "      <td>0.31802</td>\n",
       "      <td>-0.39242</td>\n",
       "      <td>-0.23394</td>\n",
       "      <td>0.47298</td>\n",
       "      <td>-0.028803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-0.1529</td>\n",
       "      <td>-0.24279</td>\n",
       "      <td>0.89837</td>\n",
       "      <td>0.16996</td>\n",
       "      <td>0.53516</td>\n",
       "      <td>0.48784</td>\n",
       "      <td>-0.58826</td>\n",
       "      <td>-0.17982</td>\n",
       "      <td>-1.3581</td>\n",
       "      <td>0.42541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18712</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.26757</td>\n",
       "      <td>0.727</td>\n",
       "      <td>-0.59363</td>\n",
       "      <td>-0.34839</td>\n",
       "      <td>-0.56094</td>\n",
       "      <td>-0.591</td>\n",
       "      <td>1.0039</td>\n",
       "      <td>0.20664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>-0.1897</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>0.19084</td>\n",
       "      <td>-0.049184</td>\n",
       "      <td>-0.089737</td>\n",
       "      <td>0.21006</td>\n",
       "      <td>-0.54952</td>\n",
       "      <td>0.098377</td>\n",
       "      <td>-0.20135</td>\n",
       "      <td>0.34241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13134</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>-0.31869</td>\n",
       "      <td>-0.61419</td>\n",
       "      <td>-0.62393</td>\n",
       "      <td>-0.41548</td>\n",
       "      <td>-0.038175</td>\n",
       "      <td>-0.39804</td>\n",
       "      <td>0.47647</td>\n",
       "      <td>-0.15983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1        2          3          4         5         6   \\\n",
       "the  -0.038194  -0.24487  0.72812   -0.39961   0.083172  0.043953  -0.39141   \n",
       ",     -0.10767   0.11053  0.59812   -0.54361    0.67396   0.10663  0.038867   \n",
       ".     -0.33979   0.20941  0.46348   -0.64792   -0.38377  0.038034   0.17127   \n",
       "of     -0.1529  -0.24279  0.89837    0.16996    0.53516   0.48784  -0.58826   \n",
       "to     -0.1897  0.050024  0.19084  -0.049184  -0.089737   0.21006  -0.54952   \n",
       "\n",
       "           7         8          9   ...         90         91         92  \\\n",
       "the    0.3344  -0.57545   0.087459  ...   0.016215  -0.017099   -0.38984   \n",
       ",     0.35481   0.06351  -0.094189  ...    0.34951    -0.7226    0.37549   \n",
       ".     0.15978   0.46619  -0.019169  ...  -0.063351   -0.67412  -0.068895   \n",
       "of   -0.17982   -1.3581    0.42541  ...    0.18712  -0.018488   -0.26757   \n",
       "to   0.098377  -0.20135    0.34241  ...   -0.13134   0.058617   -0.31869   \n",
       "\n",
       "           93        94        95         96        97       98         99  \n",
       "the   0.87424  -0.72569  -0.51058   -0.52028   -0.1459   0.8278    0.27062  \n",
       ",      0.4441  -0.99059   0.61214   -0.35111  -0.83155  0.45293   0.082577  \n",
       ".     0.53604  -0.87773   0.31802   -0.39242  -0.23394  0.47298  -0.028803  \n",
       "of      0.727  -0.59363  -0.34839   -0.56094    -0.591   1.0039    0.20664  \n",
       "to   -0.61419  -0.62393  -0.41548  -0.038175  -0.39804  0.47647   -0.15983  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdef47f",
   "metadata": {},
   "source": [
    "The above is the dataframe in which the embedd vectors for each word is given. This is just for reference and understanding. We have to check the corpus of the given text vectors and simply reduce the probable dimensions of the above Embedd Vector dimensions to keep it better and computationally less expensive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4869db3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported Files : glove.6B.100d.txt\n",
      "Imported Files : glove.6B.200d.txt\n",
      "Imported Files : glove.6B.300d.txt\n",
      "Imported Files : glove.6B.50d.txt\n"
     ]
    }
   ],
   "source": [
    "vocabulary={}\n",
    "for each in loading_preparation(project_folder):\n",
    "    vocabulary.update({each : list(prepare_df(each).index)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4a098e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backing up the data just to make sure that we don't completely loose it.\n",
    "import json\n",
    "with open('vocabulary_data.json', 'w') as file:\n",
    "    json.dump(vocabulary, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d036de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file3=open('vocabulary_data.json',\"r\")\n",
    "vocabulary=json.load(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54d95aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['D:\\\\Work_folders\\\\datasets\\\\NLP-Project2\\\\Data - Sarcasm Detection\\\\glove.6B.100d.txt', 'D:\\\\Work_folders\\\\datasets\\\\NLP-Project2\\\\Data - Sarcasm Detection\\\\glove.6B.200d.txt', 'D:\\\\Work_folders\\\\datasets\\\\NLP-Project2\\\\Data - Sarcasm Detection\\\\glove.6B.300d.txt', 'D:\\\\Work_folders\\\\datasets\\\\NLP-Project2\\\\Data - Sarcasm Detection\\\\glove.6B.50d.txt'])\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary.keys())\n",
    "d_100=list(vocabulary.keys())[0]\n",
    "d_200=list(vocabulary.keys())[1]\n",
    "d_300=list(vocabulary.keys())[2]\n",
    "d_50=list(vocabulary.keys())[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c6f0c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of documents is : 26709\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of documents is :\",len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7968c64",
   "metadata": {},
   "source": [
    "Now let us check how many number of words are there and how many will come in each iteration. For our current analysis we will stick to the 100 dimensional embedding and design a function where we can choose which one we will want to use depending upon how many words we are going to gather and how we are going to distribute them across the vector dimensions. We will take decision based on that. \n",
    "\n",
    "**Note**\n",
    "Though other higher level calls are available directly for this, we will manually do all this to get a good sense of what is going on in the background.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5b87e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d=pd.DataFrame(np.loadtxt(inp,dtype=None,delimiter=\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199b7d26",
   "metadata": {},
   "source": [
    "So, here the same Vocabulary is coded in both 50 dimensional vector, a 100 dimensional vector and also 200 and 300 dimensional Vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa971afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'sunday roundup': 10, 'the 20 funniest tweets from women this week': 10, \"'no way to prevent this,' says only nation where this regularly happens\": 8, 'the funniest tweets from parents this week': 6, 'the funniest tweets from women this week': 4, 'sole remaining lung filled with rich, satisfying flavor': 3, 'magic-markered initials fail to deter breakroom rice-cake thief': 2, 'antarctic observational comic running out of ideas': 2, 'the best chance to defeat roy moore may be for the democratic party to lie low': 2, 'pier 1 issues formal apology for rattan death march': 2, ...})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.probability import FreqDist\n",
    "nltk.FreqDist(df[\"headline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "072b21e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_distribution(Series_given):\n",
    "    words_text=[item for sublist in list(Series_given) for item in sublist]\n",
    "    return dict(FreqDist(words_text))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71aa58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df[\"headline\"]=df[\"headline\"].apply(word_tokenize)\n",
    "df[\"word_no\"]=df[\"headline\"].apply(len) # Word NO count for keeping track\n",
    "temp=list(df[\"headline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae22abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_corp=freq_distribution(df[\"headline\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffc4709",
   "metadata": {},
   "source": [
    "Let us have a brief look at the number of words that are present in each headline, by maximum and minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ccb047",
   "metadata": {},
   "source": [
    "We will have a brief discussion about this topic of how many words to keep much later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c06a1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=set(headline_corp.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f53a5",
   "metadata": {},
   "source": [
    "Now we have the corpus of words that is in headlines and now let us check what is the difference between the words that are given in the headlines corpus and the word vector that we have imported from glove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "844e8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=len(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8d2b809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total Number of unique words in the Corpus of Glove Embedding 100d are :  400000\n",
      "The total Number of unique words in the Corpus of Glove Embedding 200d are :  400000\n",
      "The total Number of unique words in the Corpus of Glove Embedding 300d are :  400000\n",
      "The total Number of unique words in the Corpus of Glove Embedding 50d are :  400000\n",
      "0 0 0\n",
      "All the word dimensions represent same set of words\n",
      "\n",
      "Total Number of Unique words in Headline Corpus is : 29280\n",
      "This number of words that are in corpus and not in 100 Dimensional Vector is : 4231\n"
     ]
    }
   ],
   "source": [
    "#First let us check with the data with the vocabulary with 100_d vectors.\n",
    "#data=json.loads(\"vocabulary_data.json\")\n",
    "test2=set(vocabulary[d_100])\n",
    "print(\"The total Number of unique words in the Corpus of Glove Embedding 100d are : \",len(test2))\n",
    "test3=set(vocabulary[d_200])\n",
    "print(\"The total Number of unique words in the Corpus of Glove Embedding 200d are : \",len(test3))\n",
    "test4=set(vocabulary[d_300])\n",
    "print(\"The total Number of unique words in the Corpus of Glove Embedding 300d are : \",len(test4))\n",
    "test5=set(vocabulary[d_50])\n",
    "print(\"The total Number of unique words in the Corpus of Glove Embedding 50d are : \",len(test5))\n",
    "print(len(test2-test3),len(test3-test4),len(test4-test5))\n",
    "#This shows the words that are present in our 100 Dimensional Glove Vector and \n",
    "# and the corpus of text we have here.\n",
    "if len(test2.intersection(test3))!=0:\n",
    "    print(\"All the word dimensions represent same set of words\\n\")\n",
    "print(\"Total Number of Unique words in Headline Corpus is :\",len(test1))\n",
    "print(\"This number of words that are in corpus and not in 100 Dimensional Vector is :\",len(test1-test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f177fcba",
   "metadata": {},
   "source": [
    "It is confirmed here that there are a total of 29280 words in Headlines corpus. Some of which are present inside the Glove vector and some aren't. So, let's do the same analysis of it after removing stop words and see if the same number of words still remain. If there are some words that still remain, we will check the frequencies of those words and decide what we will do with them.\n",
    "\n",
    "Before we proceed, since we have already established here, we are free to deal with 100_d data and we will now be dealing with only that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d65c1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sheshank_Joshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = stopwords.words('english') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76940088",
   "metadata": {},
   "source": [
    "**Before We proceed please note here**\n",
    "Glove Vector Embeddings, obviously, has few of a the punctuations too i.e. it has not been lemmatized. We leave it as it is since it is done on a much greater purpose and I am not sure what is going to happen if we eliminate vectors from vector space i.e. will they affect the integrity of the vector space or not, since clusters possibly loose their strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "881649f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total number of words that are not unique in the original corpus are :  -25049\n"
     ]
    }
   ],
   "source": [
    "print(\"The Total number of words that are not unique in the original corpus are : \",len(test1-test2)-count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a36e02",
   "metadata": {},
   "source": [
    "Now, let us do lemmatization and check if it changes or not, then we will proceed further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40dd2cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "lemmatized_corps=[lemmatizer.lemmatize(word) for word in test1 if word not in stop_words and not word.isdigit()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea5d0d",
   "metadata": {},
   "source": [
    "Checking more for the intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e669fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test6=set(lemmatized_corps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c521f",
   "metadata": {},
   "source": [
    "This is the most important set, which will decide which things wer are going to drop in future while progressing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34da02f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "don\n",
      "can\n",
      "as\n",
      "being\n",
      "t\n",
      "m\n",
      "down\n",
      "out\n"
     ]
    }
   ],
   "source": [
    "#small testing\n",
    "for each in test6:\n",
    "    if each in stop_words:\n",
    "        print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc7cc35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total number of words that are not unique in the original corpus are :  -25075\n"
     ]
    }
   ],
   "source": [
    "print(\"The Total number of words that are not unique in the original corpus are : \",len(test6-test2)-count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a0b1f4",
   "metadata": {},
   "source": [
    "So, the difference is not much. So, there are some unique words within the text corpus given to us that are not present in the glove embedding vectors. Hence, we will supply them to our embedding layers. They might actually be the key indicators as to whether something falls into the category of sarcasm or not. We can go into a considerable detail and analysis of those words, what percentage and probability does those words carry with that decide whether the contribute anything towards the decision of sarcasm or not (i.e. if they are equally distributed in both the classes of the data or not). But that's too much of an analysis not required of the problem set. So, we are moving ahead.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba92c2",
   "metadata": {},
   "source": [
    "**Further Approach**\n",
    "I am planning to go an a little advanced approach towards this and let things automate, instead of going for machine learning or nltk. I am going direclty to Keras and do as is listed very easily on the examples, as mentioned already, in the documentation itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410dcd74",
   "metadata": {},
   "source": [
    "A Little code addressing one of the problems asked for in the problem statement i.e. vocablary. Though already created, I am going to do it here once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "770adedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Function used to convert each list of tokenized words into lemmatized words\n",
    "##############################################################\n",
    "def word_lemma(sequence):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in sequence if word not in stop_words and not word.isdigit()]\n",
    "##############################################################\n",
    "# End of Function\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c20a71f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " \"'roseanne\",\n",
       " \"'\",\n",
       " 'revival',\n",
       " 'catches',\n",
       " 'up',\n",
       " 'to',\n",
       " 'our',\n",
       " 'thorny',\n",
       " 'political',\n",
       " 'mood',\n",
       " ',',\n",
       " 'for',\n",
       " 'better',\n",
       " 'and',\n",
       " 'worse']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"headline\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e8ba374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'roseanne\",\n",
       " 'revival',\n",
       " 'catch',\n",
       " 'thorny',\n",
       " 'political',\n",
       " 'mood',\n",
       " 'better',\n",
       " 'worse']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"headline\"].apply(word_lemma)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86f4d5",
   "metadata": {},
   "source": [
    "We can see the significant difference here in the number of non-obvious and frequent words that might actually contribute to the sarcastic tone of the headlines. But, let us wait and see how this pans out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d78f5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"headline\"]=df[\"headline\"].apply(word_lemma)\n",
    "df[\"len_2\"]=df[\"headline\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d8f4bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>length</th>\n",
       "      <th>word_no</th>\n",
       "      <th>len_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>[former, versace, store, clerk, sue, secret, '...</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>['roseanne, revival, catch, thorny, political,...</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>[mom, starting, fear, son, 's, web, series, cl...</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>[boehner, want, wife, listen, come, alternativ...</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>[j.k., rowling, wish, snape, happy, birthday, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  length  \\\n",
       "0  [former, versace, store, clerk, sue, secret, '...             0      78   \n",
       "1  ['roseanne, revival, catch, thorny, political,...             0      84   \n",
       "2  [mom, starting, fear, son, 's, web, series, cl...             1      79   \n",
       "3  [boehner, want, wife, listen, come, alternativ...             1      84   \n",
       "4  [j.k., rowling, wish, snape, happy, birthday, ...             0      64   \n",
       "\n",
       "   word_no  len_2  \n",
       "0       13     10  \n",
       "1       16      8  \n",
       "2       15     10  \n",
       "3       14      8  \n",
       "4       11      8  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f96dfef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    26709.000000\n",
       "mean         7.217530\n",
       "std          2.377083\n",
       "min          0.000000\n",
       "25%          6.000000\n",
       "50%          7.000000\n",
       "75%          9.000000\n",
       "max         27.000000\n",
       "Name: len_2, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"len_2\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3bcce3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2c657d16790>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(df[\"len_2\"]) # A quick check on how the number of words is distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785cc270",
   "metadata": {},
   "source": [
    "Since there are very few words in the whole of the headlines, it is only negatively rewarding to do anything to it like POS tagging or something similar. So, lets leave it there and have a brief look at the entries where there are no words after lemmatization, indicating that most probably they were filled with stop words. That means they don't obviously carry that much of a meaning, or that they may be in conjunction with the original text of the article. It is beyond the scope of the problem statement. Hence, it is not being considered here. So, only a brief look at the count of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59424f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>length</th>\n",
       "      <th>word_no</th>\n",
       "      <th>len_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5322</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/i-was-but...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           article_link headline  \\\n",
       "5322  https://www.huffingtonpost.com/entry/i-was-but...       []   \n",
       "\n",
       "      is_sarcastic  length  word_no  len_2  \n",
       "5322             0      19        7      0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"len_2\"]==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d48c1",
   "metadata": {},
   "source": [
    "Thankfully, there is only one headline where the headlines are filled with stop words. \n",
    "\n",
    "**Some Observations and Notices**\n",
    "\n",
    "Once again, I reiterate the third time that it is completely contextual of the Current prevailing situation that will decide whether a word will contribute towards generating sarcasm or not. Sometimes, even the entire corpus of the original article might not be able to sufficient to explain whether what we have observed a certain pattern. As far as my knowledge goes, it all depends on the day it is published, and the current prevailing sitautions of the time along with immediate events that were leading upto it or may follow it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b21d5fe",
   "metadata": {},
   "source": [
    "Let us now prepare a complete word vocabulary with index and initialized word vectors and properly place it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e841bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index.name=\"word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abb7c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2=data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d577e866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'the',\n",
       " 1: ',',\n",
       " 2: '.',\n",
       " 3: 'of',\n",
       " 4: 'to',\n",
       " 5: 'and',\n",
       " 6: 'in',\n",
       " 7: 'a',\n",
       " 8: '\"',\n",
       " 9: \"'s\",\n",
       " 10: 'for',\n",
       " 11: '-',\n",
       " 12: 'that',\n",
       " 13: 'on',\n",
       " 14: 'is',\n",
       " 15: 'was',\n",
       " 16: 'said',\n",
       " 17: 'with',\n",
       " 18: 'he',\n",
       " 19: 'as',\n",
       " 20: 'it',\n",
       " 21: 'by',\n",
       " 22: 'at',\n",
       " 23: '(',\n",
       " 24: ')',\n",
       " 25: 'from',\n",
       " 26: 'his',\n",
       " 27: \"''\",\n",
       " 28: '``',\n",
       " 29: 'an',\n",
       " 30: 'be',\n",
       " 31: 'has',\n",
       " 32: 'are',\n",
       " 33: 'have',\n",
       " 34: 'but',\n",
       " 35: 'were',\n",
       " 36: 'not',\n",
       " 37: 'this',\n",
       " 38: 'who',\n",
       " 39: 'they',\n",
       " 40: 'had',\n",
       " 41: 'i',\n",
       " 42: 'which',\n",
       " 43: 'will',\n",
       " 44: 'their',\n",
       " 45: ':',\n",
       " 46: 'or',\n",
       " 47: 'its',\n",
       " 48: 'one',\n",
       " 49: 'after',\n",
       " 50: 'new',\n",
       " 51: 'been',\n",
       " 52: 'also',\n",
       " 53: 'we',\n",
       " 54: 'would',\n",
       " 55: 'two',\n",
       " 56: 'more',\n",
       " 57: \"'\",\n",
       " 58: 'first',\n",
       " 59: 'about',\n",
       " 60: 'up',\n",
       " 61: 'when',\n",
       " 62: 'year',\n",
       " 63: 'there',\n",
       " 64: 'all',\n",
       " 65: '--',\n",
       " 66: 'out',\n",
       " 67: 'she',\n",
       " 68: 'other',\n",
       " 69: 'people',\n",
       " 70: \"n't\",\n",
       " 71: 'her',\n",
       " 72: 'percent',\n",
       " 73: 'than',\n",
       " 74: 'over',\n",
       " 75: 'into',\n",
       " 76: 'last',\n",
       " 77: 'some',\n",
       " 78: 'government',\n",
       " 79: 'time',\n",
       " 80: '$',\n",
       " 81: 'you',\n",
       " 82: 'years',\n",
       " 83: 'if',\n",
       " 84: 'no',\n",
       " 85: 'world',\n",
       " 86: 'can',\n",
       " 87: 'three',\n",
       " 88: 'do',\n",
       " 89: ';',\n",
       " 90: 'president',\n",
       " 91: 'only',\n",
       " 92: 'state',\n",
       " 93: 'million',\n",
       " 94: 'could',\n",
       " 95: 'us',\n",
       " 96: 'most',\n",
       " 97: '_',\n",
       " 98: 'against',\n",
       " 99: 'u.s.',\n",
       " 100: 'so',\n",
       " 101: 'them',\n",
       " 102: 'what',\n",
       " 103: 'him',\n",
       " 104: 'united',\n",
       " 105: 'during',\n",
       " 106: 'before',\n",
       " 107: 'may',\n",
       " 108: 'since',\n",
       " 109: 'many',\n",
       " 110: 'while',\n",
       " 111: 'where',\n",
       " 112: 'states',\n",
       " 113: 'because',\n",
       " 114: 'now',\n",
       " 115: 'city',\n",
       " 116: 'made',\n",
       " 117: 'like',\n",
       " 118: 'between',\n",
       " 119: 'did',\n",
       " 120: 'just',\n",
       " 121: 'national',\n",
       " 122: 'day',\n",
       " 123: 'country',\n",
       " 124: 'under',\n",
       " 125: 'such',\n",
       " 126: 'second',\n",
       " 127: 'then',\n",
       " 128: 'company',\n",
       " 129: 'group',\n",
       " 130: 'any',\n",
       " 131: 'through',\n",
       " 132: 'china',\n",
       " 133: 'four',\n",
       " 134: 'being',\n",
       " 135: 'down',\n",
       " 136: 'war',\n",
       " 137: 'back',\n",
       " 138: 'off',\n",
       " 139: 'south',\n",
       " 140: 'american',\n",
       " 141: 'minister',\n",
       " 142: 'police',\n",
       " 143: 'well',\n",
       " 144: 'including',\n",
       " 145: 'team',\n",
       " 146: 'international',\n",
       " 147: 'week',\n",
       " 148: 'officials',\n",
       " 149: 'still',\n",
       " 150: 'both',\n",
       " 151: 'even',\n",
       " 152: 'high',\n",
       " 153: 'part',\n",
       " 154: 'told',\n",
       " 155: 'those',\n",
       " 156: 'end',\n",
       " 157: 'former',\n",
       " 158: 'these',\n",
       " 159: 'make',\n",
       " 160: 'billion',\n",
       " 161: 'work',\n",
       " 162: 'our',\n",
       " 163: 'home',\n",
       " 164: 'school',\n",
       " 165: 'party',\n",
       " 166: 'house',\n",
       " 167: 'old',\n",
       " 168: 'later',\n",
       " 169: 'get',\n",
       " 170: 'another',\n",
       " 171: 'tuesday',\n",
       " 172: 'news',\n",
       " 173: 'long',\n",
       " 174: 'five',\n",
       " 175: 'called',\n",
       " 176: '1',\n",
       " 177: 'wednesday',\n",
       " 178: 'military',\n",
       " 179: 'way',\n",
       " 180: 'used',\n",
       " 181: 'much',\n",
       " 182: 'next',\n",
       " 183: 'monday',\n",
       " 184: 'thursday',\n",
       " 185: 'friday',\n",
       " 186: 'game',\n",
       " 187: 'here',\n",
       " 188: '?',\n",
       " 189: 'should',\n",
       " 190: 'take',\n",
       " 191: 'very',\n",
       " 192: 'my',\n",
       " 193: 'north',\n",
       " 194: 'security',\n",
       " 195: 'season',\n",
       " 196: 'york',\n",
       " 197: 'how',\n",
       " 198: 'public',\n",
       " 199: 'early',\n",
       " 200: 'according',\n",
       " 201: 'several',\n",
       " 202: 'court',\n",
       " 203: 'say',\n",
       " 204: 'around',\n",
       " 205: 'foreign',\n",
       " 206: '10',\n",
       " 207: 'until',\n",
       " 208: 'set',\n",
       " 209: 'political',\n",
       " 210: 'says',\n",
       " 211: 'market',\n",
       " 212: 'however',\n",
       " 213: 'family',\n",
       " 214: 'life',\n",
       " 215: 'same',\n",
       " 216: 'general',\n",
       " 217: '–',\n",
       " 218: 'left',\n",
       " 219: 'good',\n",
       " 220: 'top',\n",
       " 221: 'university',\n",
       " 222: 'going',\n",
       " 223: 'number',\n",
       " 224: 'major',\n",
       " 225: 'known',\n",
       " 226: 'points',\n",
       " 227: 'won',\n",
       " 228: 'six',\n",
       " 229: 'month',\n",
       " 230: 'dollars',\n",
       " 231: 'bank',\n",
       " 232: '2',\n",
       " 233: 'iraq',\n",
       " 234: 'use',\n",
       " 235: 'members',\n",
       " 236: 'each',\n",
       " 237: 'area',\n",
       " 238: 'found',\n",
       " 239: 'official',\n",
       " 240: 'sunday',\n",
       " 241: 'place',\n",
       " 242: 'go',\n",
       " 243: 'based',\n",
       " 244: 'among',\n",
       " 245: 'third',\n",
       " 246: 'times',\n",
       " 247: 'took',\n",
       " 248: 'right',\n",
       " 249: 'days',\n",
       " 250: 'local',\n",
       " 251: 'economic',\n",
       " 252: 'countries',\n",
       " 253: 'see',\n",
       " 254: 'best',\n",
       " 255: 'report',\n",
       " 256: 'killed',\n",
       " 257: 'held',\n",
       " 258: 'business',\n",
       " 259: 'west',\n",
       " 260: 'does',\n",
       " 261: 'own',\n",
       " 262: '%',\n",
       " 263: 'came',\n",
       " 264: 'law',\n",
       " 265: 'months',\n",
       " 266: 'women',\n",
       " 267: \"'re\",\n",
       " 268: 'power',\n",
       " 269: 'think',\n",
       " 270: 'service',\n",
       " 271: 'children',\n",
       " 272: 'bush',\n",
       " 273: 'show',\n",
       " 274: '/',\n",
       " 275: 'help',\n",
       " 276: 'chief',\n",
       " 277: 'saturday',\n",
       " 278: 'system',\n",
       " 279: 'john',\n",
       " 280: 'support',\n",
       " 281: 'series',\n",
       " 282: 'play',\n",
       " 283: 'office',\n",
       " 284: 'following',\n",
       " 285: 'me',\n",
       " 286: 'meeting',\n",
       " 287: 'expected',\n",
       " 288: 'late',\n",
       " 289: 'washington',\n",
       " 290: 'games',\n",
       " 291: 'european',\n",
       " 292: 'league',\n",
       " 293: 'reported',\n",
       " 294: 'final',\n",
       " 295: 'added',\n",
       " 296: 'without',\n",
       " 297: 'british',\n",
       " 298: 'white',\n",
       " 299: 'history',\n",
       " 300: 'man',\n",
       " 301: 'men',\n",
       " 302: 'became',\n",
       " 303: 'want',\n",
       " 304: 'march',\n",
       " 305: 'case',\n",
       " 306: 'few',\n",
       " 307: 'run',\n",
       " 308: 'money',\n",
       " 309: 'began',\n",
       " 310: 'open',\n",
       " 311: 'name',\n",
       " 312: 'trade',\n",
       " 313: 'center',\n",
       " 314: '3',\n",
       " 315: 'israel',\n",
       " 316: 'oil',\n",
       " 317: 'too',\n",
       " 318: 'al',\n",
       " 319: 'film',\n",
       " 320: 'win',\n",
       " 321: 'led',\n",
       " 322: 'east',\n",
       " 323: 'central',\n",
       " 324: '20',\n",
       " 325: 'air',\n",
       " 326: 'come',\n",
       " 327: 'chinese',\n",
       " 328: 'town',\n",
       " 329: 'leader',\n",
       " 330: 'army',\n",
       " 331: 'line',\n",
       " 332: 'never',\n",
       " 333: 'little',\n",
       " 334: 'played',\n",
       " 335: 'prime',\n",
       " 336: 'death',\n",
       " 337: 'companies',\n",
       " 338: 'least',\n",
       " 339: 'put',\n",
       " 340: 'forces',\n",
       " 341: 'past',\n",
       " 342: 'de',\n",
       " 343: 'half',\n",
       " 344: 'june',\n",
       " 345: 'saying',\n",
       " 346: 'know',\n",
       " 347: 'federal',\n",
       " 348: 'french',\n",
       " 349: 'peace',\n",
       " 350: 'earlier',\n",
       " 351: 'capital',\n",
       " 352: 'force',\n",
       " 353: 'great',\n",
       " 354: 'union',\n",
       " 355: 'near',\n",
       " 356: 'released',\n",
       " 357: 'small',\n",
       " 358: 'department',\n",
       " 359: 'every',\n",
       " 360: 'health',\n",
       " 361: 'japan',\n",
       " 362: 'head',\n",
       " 363: 'ago',\n",
       " 364: 'night',\n",
       " 365: 'big',\n",
       " 366: 'cup',\n",
       " 367: 'election',\n",
       " 368: 'region',\n",
       " 369: 'director',\n",
       " 370: 'talks',\n",
       " 371: 'program',\n",
       " 372: 'far',\n",
       " 373: 'today',\n",
       " 374: 'statement',\n",
       " 375: 'july',\n",
       " 376: 'although',\n",
       " 377: 'district',\n",
       " 378: 'again',\n",
       " 379: 'born',\n",
       " 380: 'development',\n",
       " 381: 'leaders',\n",
       " 382: 'council',\n",
       " 383: 'close',\n",
       " 384: 'record',\n",
       " 385: 'along',\n",
       " 386: 'county',\n",
       " 387: 'france',\n",
       " 388: 'went',\n",
       " 389: 'point',\n",
       " 390: 'must',\n",
       " 391: 'spokesman',\n",
       " 392: 'your',\n",
       " 393: 'member',\n",
       " 394: 'plan',\n",
       " 395: 'financial',\n",
       " 396: 'april',\n",
       " 397: 'recent',\n",
       " 398: 'campaign',\n",
       " 399: 'become',\n",
       " 400: 'troops',\n",
       " 401: 'whether',\n",
       " 402: 'lost',\n",
       " 403: 'music',\n",
       " 404: '15',\n",
       " 405: 'got',\n",
       " 406: 'israeli',\n",
       " 407: '30',\n",
       " 408: 'need',\n",
       " 409: '4',\n",
       " 410: 'lead',\n",
       " 411: 'already',\n",
       " 412: 'russia',\n",
       " 413: 'though',\n",
       " 414: 'might',\n",
       " 415: 'free',\n",
       " 416: 'hit',\n",
       " 417: 'rights',\n",
       " 418: '11',\n",
       " 419: 'information',\n",
       " 420: 'away',\n",
       " 421: '12',\n",
       " 422: '5',\n",
       " 423: 'others',\n",
       " 424: 'control',\n",
       " 425: 'within',\n",
       " 426: 'large',\n",
       " 427: 'economy',\n",
       " 428: 'press',\n",
       " 429: 'agency',\n",
       " 430: 'water',\n",
       " 431: 'died',\n",
       " 432: 'career',\n",
       " 433: 'making',\n",
       " 434: '...',\n",
       " 435: 'deal',\n",
       " 436: 'attack',\n",
       " 437: 'side',\n",
       " 438: 'seven',\n",
       " 439: 'better',\n",
       " 440: 'less',\n",
       " 441: 'september',\n",
       " 442: 'once',\n",
       " 443: 'clinton',\n",
       " 444: 'main',\n",
       " 445: 'due',\n",
       " 446: 'committee',\n",
       " 447: 'building',\n",
       " 448: 'conference',\n",
       " 449: 'club',\n",
       " 450: 'january',\n",
       " 451: 'decision',\n",
       " 452: 'stock',\n",
       " 453: 'america',\n",
       " 454: 'given',\n",
       " 455: 'give',\n",
       " 456: 'often',\n",
       " 457: 'announced',\n",
       " 458: 'television',\n",
       " 459: 'industry',\n",
       " 460: 'order',\n",
       " 461: 'young',\n",
       " 462: \"'ve\",\n",
       " 463: 'palestinian',\n",
       " 464: 'age',\n",
       " 465: 'start',\n",
       " 466: 'administration',\n",
       " 467: 'russian',\n",
       " 468: 'prices',\n",
       " 469: 'round',\n",
       " 470: 'december',\n",
       " 471: 'nations',\n",
       " 472: \"'m\",\n",
       " 473: 'human',\n",
       " 474: 'india',\n",
       " 475: 'defense',\n",
       " 476: 'asked',\n",
       " 477: 'total',\n",
       " 478: 'october',\n",
       " 479: 'players',\n",
       " 480: 'bill',\n",
       " 481: 'important',\n",
       " 482: 'southern',\n",
       " 483: 'move',\n",
       " 484: 'fire',\n",
       " 485: 'population',\n",
       " 486: 'rose',\n",
       " 487: 'november',\n",
       " 488: 'include',\n",
       " 489: 'further',\n",
       " 490: 'nuclear',\n",
       " 491: 'street',\n",
       " 492: 'taken',\n",
       " 493: 'media',\n",
       " 494: 'different',\n",
       " 495: 'issue',\n",
       " 496: 'received',\n",
       " 497: 'secretary',\n",
       " 498: 'return',\n",
       " 499: 'college',\n",
       " 500: 'working',\n",
       " 501: 'community',\n",
       " 502: 'eight',\n",
       " 503: 'groups',\n",
       " 504: 'despite',\n",
       " 505: 'level',\n",
       " 506: 'largest',\n",
       " 507: 'whose',\n",
       " 508: 'attacks',\n",
       " 509: 'germany',\n",
       " 510: 'august',\n",
       " 511: 'change',\n",
       " 512: 'church',\n",
       " 513: 'nation',\n",
       " 514: 'german',\n",
       " 515: 'station',\n",
       " 516: 'london',\n",
       " 517: 'weeks',\n",
       " 518: 'having',\n",
       " 519: '18',\n",
       " 520: 'research',\n",
       " 521: 'black',\n",
       " 522: 'services',\n",
       " 523: 'story',\n",
       " 524: '6',\n",
       " 525: 'europe',\n",
       " 526: 'sales',\n",
       " 527: 'policy',\n",
       " 528: 'visit',\n",
       " 529: 'northern',\n",
       " 530: 'lot',\n",
       " 531: 'across',\n",
       " 532: 'per',\n",
       " 533: 'current',\n",
       " 534: 'board',\n",
       " 535: 'football',\n",
       " 536: 'ministry',\n",
       " 537: 'workers',\n",
       " 538: 'vote',\n",
       " 539: 'book',\n",
       " 540: 'fell',\n",
       " 541: 'seen',\n",
       " 542: 'role',\n",
       " 543: 'students',\n",
       " 544: 'shares',\n",
       " 545: 'iran',\n",
       " 546: 'process',\n",
       " 547: 'agreement',\n",
       " 548: 'quarter',\n",
       " 549: 'full',\n",
       " 550: 'match',\n",
       " 551: 'started',\n",
       " 552: 'growth',\n",
       " 553: 'yet',\n",
       " 554: 'moved',\n",
       " 555: 'possible',\n",
       " 556: 'western',\n",
       " 557: 'special',\n",
       " 558: '100',\n",
       " 559: 'plans',\n",
       " 560: 'interest',\n",
       " 561: 'behind',\n",
       " 562: 'strong',\n",
       " 563: 'england',\n",
       " 564: 'named',\n",
       " 565: 'food',\n",
       " 566: 'period',\n",
       " 567: 'real',\n",
       " 568: 'authorities',\n",
       " 569: 'car',\n",
       " 570: 'term',\n",
       " 571: 'rate',\n",
       " 572: 'race',\n",
       " 573: 'nearly',\n",
       " 574: 'korea',\n",
       " 575: 'enough',\n",
       " 576: 'site',\n",
       " 577: 'opposition',\n",
       " 578: 'keep',\n",
       " 579: '25',\n",
       " 580: 'call',\n",
       " 581: 'future',\n",
       " 582: 'taking',\n",
       " 583: 'island',\n",
       " 584: '2008',\n",
       " 585: '2006',\n",
       " 586: 'road',\n",
       " 587: 'outside',\n",
       " 588: 'really',\n",
       " 589: 'century',\n",
       " 590: 'democratic',\n",
       " 591: 'almost',\n",
       " 592: 'single',\n",
       " 593: 'share',\n",
       " 594: 'leading',\n",
       " 595: 'trying',\n",
       " 596: 'find',\n",
       " 597: 'album',\n",
       " 598: 'senior',\n",
       " 599: 'minutes',\n",
       " 600: 'together',\n",
       " 601: 'congress',\n",
       " 602: 'index',\n",
       " 603: 'australia',\n",
       " 604: 'results',\n",
       " 605: 'hard',\n",
       " 606: 'hours',\n",
       " 607: 'land',\n",
       " 608: 'action',\n",
       " 609: 'higher',\n",
       " 610: 'field',\n",
       " 611: 'cut',\n",
       " 612: 'coach',\n",
       " 613: 'elections',\n",
       " 614: 'san',\n",
       " 615: 'issues',\n",
       " 616: 'executive',\n",
       " 617: 'february',\n",
       " 618: 'production',\n",
       " 619: 'areas',\n",
       " 620: 'river',\n",
       " 621: 'face',\n",
       " 622: 'using',\n",
       " 623: 'japanese',\n",
       " 624: 'province',\n",
       " 625: 'park',\n",
       " 626: 'price',\n",
       " 627: 'commission',\n",
       " 628: 'california',\n",
       " 629: 'father',\n",
       " 630: 'son',\n",
       " 631: 'education',\n",
       " 632: '7',\n",
       " 633: 'village',\n",
       " 634: 'energy',\n",
       " 635: 'shot',\n",
       " 636: 'short',\n",
       " 637: 'africa',\n",
       " 638: 'key',\n",
       " 639: 'red',\n",
       " 640: 'association',\n",
       " 641: 'average',\n",
       " 642: 'pay',\n",
       " 643: 'exchange',\n",
       " 644: 'eu',\n",
       " 645: 'something',\n",
       " 646: 'gave',\n",
       " 647: 'likely',\n",
       " 648: 'player',\n",
       " 649: 'george',\n",
       " 650: '2007',\n",
       " 651: 'victory',\n",
       " 652: '8',\n",
       " 653: 'low',\n",
       " 654: 'things',\n",
       " 655: '2010',\n",
       " 656: 'pakistan',\n",
       " 657: '14',\n",
       " 658: 'post',\n",
       " 659: 'social',\n",
       " 660: 'continue',\n",
       " 661: 'ever',\n",
       " 662: 'look',\n",
       " 663: 'chairman',\n",
       " 664: 'job',\n",
       " 665: '2000',\n",
       " 666: 'soldiers',\n",
       " 667: 'able',\n",
       " 668: 'parliament',\n",
       " 669: 'front',\n",
       " 670: 'himself',\n",
       " 671: 'problems',\n",
       " 672: 'private',\n",
       " 673: 'lower',\n",
       " 674: 'list',\n",
       " 675: 'built',\n",
       " 676: '13',\n",
       " 677: 'efforts',\n",
       " 678: 'dollar',\n",
       " 679: 'miles',\n",
       " 680: 'included',\n",
       " 681: 'radio',\n",
       " 682: 'live',\n",
       " 683: 'form',\n",
       " 684: 'david',\n",
       " 685: 'african',\n",
       " 686: 'increase',\n",
       " 687: 'reports',\n",
       " 688: 'sent',\n",
       " 689: 'fourth',\n",
       " 690: 'always',\n",
       " 691: 'king',\n",
       " 692: '50',\n",
       " 693: 'tax',\n",
       " 694: 'taiwan',\n",
       " 695: 'britain',\n",
       " 696: '16',\n",
       " 697: 'playing',\n",
       " 698: 'title',\n",
       " 699: 'middle',\n",
       " 700: 'meet',\n",
       " 701: 'global',\n",
       " 702: 'wife',\n",
       " 703: '2009',\n",
       " 704: 'position',\n",
       " 705: 'located',\n",
       " 706: 'clear',\n",
       " 707: 'ahead',\n",
       " 708: '2004',\n",
       " 709: '2005',\n",
       " 710: 'iraqi',\n",
       " 711: 'english',\n",
       " 712: 'result',\n",
       " 713: 'release',\n",
       " 714: 'violence',\n",
       " 715: 'goal',\n",
       " 716: 'project',\n",
       " 717: 'closed',\n",
       " 718: 'border',\n",
       " 719: 'body',\n",
       " 720: 'soon',\n",
       " 721: 'crisis',\n",
       " 722: 'division',\n",
       " 723: '&amp;',\n",
       " 724: 'served',\n",
       " 725: 'tour',\n",
       " 726: 'hospital',\n",
       " 727: 'kong',\n",
       " 728: 'test',\n",
       " 729: 'hong',\n",
       " 730: 'u.n.',\n",
       " 731: 'inc.',\n",
       " 732: 'technology',\n",
       " 733: 'believe',\n",
       " 734: 'organization',\n",
       " 735: 'published',\n",
       " 736: 'weapons',\n",
       " 737: 'agreed',\n",
       " 738: 'why',\n",
       " 739: 'nine',\n",
       " 740: 'summer',\n",
       " 741: 'wanted',\n",
       " 742: 'republican',\n",
       " 743: 'act',\n",
       " 744: 'recently',\n",
       " 745: 'texas',\n",
       " 746: 'course',\n",
       " 747: 'problem',\n",
       " 748: 'senate',\n",
       " 749: 'medical',\n",
       " 750: 'un',\n",
       " 751: 'done',\n",
       " 752: 'reached',\n",
       " 753: 'star',\n",
       " 754: 'continued',\n",
       " 755: 'investors',\n",
       " 756: 'living',\n",
       " 757: 'care',\n",
       " 758: 'signed',\n",
       " 759: '17',\n",
       " 760: 'art',\n",
       " 761: 'provide',\n",
       " 762: 'worked',\n",
       " 763: 'presidential',\n",
       " 764: 'gold',\n",
       " 765: 'obama',\n",
       " 766: 'morning',\n",
       " 767: 'dead',\n",
       " 768: 'opened',\n",
       " 769: \"'ll\",\n",
       " 770: 'event',\n",
       " 771: 'previous',\n",
       " 772: 'cost',\n",
       " 773: 'instead',\n",
       " 774: 'canada',\n",
       " 775: 'band',\n",
       " 776: 'teams',\n",
       " 777: 'daily',\n",
       " 778: '2001',\n",
       " 779: 'available',\n",
       " 780: 'drug',\n",
       " 781: 'coming',\n",
       " 782: '2003',\n",
       " 783: 'investment',\n",
       " 784: '’s',\n",
       " 785: 'michael',\n",
       " 786: 'civil',\n",
       " 787: 'woman',\n",
       " 788: 'training',\n",
       " 789: 'appeared',\n",
       " 790: '9',\n",
       " 791: 'involved',\n",
       " 792: 'indian',\n",
       " 793: 'similar',\n",
       " 794: 'situation',\n",
       " 795: '24',\n",
       " 796: 'los',\n",
       " 797: 'running',\n",
       " 798: 'fighting',\n",
       " 799: 'mark',\n",
       " 800: '40',\n",
       " 801: 'trial',\n",
       " 802: 'hold',\n",
       " 803: 'australian',\n",
       " 804: 'thought',\n",
       " 805: '!',\n",
       " 806: 'study',\n",
       " 807: 'fall',\n",
       " 808: 'mother',\n",
       " 809: 'met',\n",
       " 810: 'relations',\n",
       " 811: 'anti',\n",
       " 812: '2002',\n",
       " 813: 'song',\n",
       " 814: 'popular',\n",
       " 815: 'base',\n",
       " 816: 'tv',\n",
       " 817: 'ground',\n",
       " 818: 'markets',\n",
       " 819: 'ii',\n",
       " 820: 'newspaper',\n",
       " 821: 'staff',\n",
       " 822: 'saw',\n",
       " 823: 'hand',\n",
       " 824: 'hope',\n",
       " 825: 'operations',\n",
       " 826: 'pressure',\n",
       " 827: 'americans',\n",
       " 828: 'eastern',\n",
       " 829: 'st.',\n",
       " 830: 'legal',\n",
       " 831: 'asia',\n",
       " 832: 'budget',\n",
       " 833: 'returned',\n",
       " 834: 'considered',\n",
       " 835: 'love',\n",
       " 836: 'wrote',\n",
       " 837: 'stop',\n",
       " 838: 'fight',\n",
       " 839: 'currently',\n",
       " 840: 'charges',\n",
       " 841: 'try',\n",
       " 842: 'aid',\n",
       " 843: 'ended',\n",
       " 844: 'management',\n",
       " 845: 'brought',\n",
       " 846: 'cases',\n",
       " 847: 'decided',\n",
       " 848: 'failed',\n",
       " 849: 'network',\n",
       " 850: 'works',\n",
       " 851: 'gas',\n",
       " 852: 'turned',\n",
       " 853: 'fact',\n",
       " 854: 'vice',\n",
       " 855: 'ca',\n",
       " 856: 'mexico',\n",
       " 857: 'trading',\n",
       " 858: 'especially',\n",
       " 859: 'reporters',\n",
       " 860: 'afghanistan',\n",
       " 861: 'common',\n",
       " 862: 'looking',\n",
       " 863: 'space',\n",
       " 864: 'rates',\n",
       " 865: 'manager',\n",
       " 866: 'loss',\n",
       " 867: '2011',\n",
       " 868: 'justice',\n",
       " 869: 'thousands',\n",
       " 870: 'james',\n",
       " 871: 'rather',\n",
       " 872: 'fund',\n",
       " 873: 'thing',\n",
       " 874: 'republic',\n",
       " 875: 'opening',\n",
       " 876: 'accused',\n",
       " 877: 'winning',\n",
       " 878: 'scored',\n",
       " 879: 'championship',\n",
       " 880: 'example',\n",
       " 881: 'getting',\n",
       " 882: 'biggest',\n",
       " 883: 'performance',\n",
       " 884: 'sports',\n",
       " 885: '1998',\n",
       " 886: 'let',\n",
       " 887: 'allowed',\n",
       " 888: 'schools',\n",
       " 889: 'means',\n",
       " 890: 'turn',\n",
       " 891: 'leave',\n",
       " 892: 'no.',\n",
       " 893: 'robert',\n",
       " 894: 'personal',\n",
       " 895: 'stocks',\n",
       " 896: 'showed',\n",
       " 897: 'light',\n",
       " 898: 'arrested',\n",
       " 899: 'person',\n",
       " 900: 'either',\n",
       " 901: 'offer',\n",
       " 902: 'majority',\n",
       " 903: 'battle',\n",
       " 904: '19',\n",
       " 905: 'class',\n",
       " 906: 'evidence',\n",
       " 907: 'makes',\n",
       " 908: 'society',\n",
       " 909: 'products',\n",
       " 910: 'regional',\n",
       " 911: 'needed',\n",
       " 912: 'stage',\n",
       " 913: 'am',\n",
       " 914: 'doing',\n",
       " 915: 'families',\n",
       " 916: 'construction',\n",
       " 917: 'various',\n",
       " 918: '1996',\n",
       " 919: 'sold',\n",
       " 920: 'independent',\n",
       " 921: 'kind',\n",
       " 922: 'airport',\n",
       " 923: 'paul',\n",
       " 924: 'judge',\n",
       " 925: 'internet',\n",
       " 926: 'movement',\n",
       " 927: 'room',\n",
       " 928: 'followed',\n",
       " 929: 'original',\n",
       " 930: 'angeles',\n",
       " 931: 'italy',\n",
       " 932: '`',\n",
       " 933: 'data',\n",
       " 934: 'comes',\n",
       " 935: 'parties',\n",
       " 936: 'nothing',\n",
       " 937: 'sea',\n",
       " 938: 'bring',\n",
       " 939: '2012',\n",
       " 940: 'annual',\n",
       " 941: 'officer',\n",
       " 942: 'beijing',\n",
       " 943: 'present',\n",
       " 944: 'remain',\n",
       " 945: 'nato',\n",
       " 946: '1999',\n",
       " 947: '22',\n",
       " 948: 'remains',\n",
       " 949: 'allow',\n",
       " 950: 'florida',\n",
       " 951: 'computer',\n",
       " 952: '21',\n",
       " 953: 'contract',\n",
       " 954: 'coast',\n",
       " 955: 'created',\n",
       " 956: 'demand',\n",
       " 957: 'operation',\n",
       " 958: 'events',\n",
       " 959: 'islamic',\n",
       " 960: 'beat',\n",
       " 961: 'analysts',\n",
       " 962: 'interview',\n",
       " 963: 'helped',\n",
       " 964: 'child',\n",
       " 965: 'probably',\n",
       " 966: 'spent',\n",
       " 967: 'asian',\n",
       " 968: 'effort',\n",
       " 969: 'cooperation',\n",
       " 970: 'shows',\n",
       " 971: 'calls',\n",
       " 972: 'investigation',\n",
       " 973: 'lives',\n",
       " 974: 'video',\n",
       " 975: 'yen',\n",
       " 976: 'runs',\n",
       " 977: 'tried',\n",
       " 978: 'bad',\n",
       " 979: 'described',\n",
       " 980: '1994',\n",
       " 981: 'toward',\n",
       " 982: 'written',\n",
       " 983: 'throughout',\n",
       " 984: 'established',\n",
       " 985: 'mission',\n",
       " 986: 'associated',\n",
       " 987: 'buy',\n",
       " 988: 'growing',\n",
       " 989: 'green',\n",
       " 990: 'forward',\n",
       " 991: 'competition',\n",
       " 992: 'poor',\n",
       " 993: 'latest',\n",
       " 994: 'banks',\n",
       " 995: 'question',\n",
       " 996: '1997',\n",
       " 997: 'prison',\n",
       " 998: 'feel',\n",
       " 999: 'attention',\n",
       " ...}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_final=dict(data_2[\"word\"]) #To this series we will try to append our missing words based on frequency distribution\n",
    "vocab_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b995be",
   "metadata": {},
   "source": [
    "We have to recreate our frequency distribution, since we have already lemmatized the words and eliminated a lot of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1527230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_corp=pd.Series(freq_distribution(df[\"headline\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24048954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the            202\n",
       "'we              36\n",
       "'snl             36\n",
       "'you             36\n",
       "'it              35\n",
       "               ... \n",
       "'kill             1\n",
       "salt-assault      1\n",
       "smug-bastard      1\n",
       "'fearful          1\n",
       "'wipe             1\n",
       "Length: 4205, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_corp.loc[test6-test2].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca07ce",
   "metadata": {},
   "source": [
    "Looks like there are some unusual number of words out htere, especially with punctuation and all. I have checked it- but not included here - that these some words escaped our lemmatization process and stop words. That usually because they accompanied quotes. Quotes are the most important and genuine way to actually figure out sarcasm in any kind of sentence. So, I am going to retain them and use it for my model ahead and add it for vocabulary. We can do further research into how we can differentiate these words, and how we can eliminate worthy individuals for sarcasm against the fooling ones. But, I am not going to go there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e637ed64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of words that are present in the import but in our corpus is :  378295\n"
     ]
    }
   ],
   "source": [
    "irrelevant_words=test2-test6\n",
    "print(\"Total Number of words that are present in the import but in our corpus is : \",len(irrelevant_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab294a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"irrelevant_words.json\",\"w\")\n",
    "json.dump(list(irrelevant_words),file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db2e970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_words=headline_corp.loc[test6-test2].index\n",
    "file=open(\"extra_words.json\",\"w\")\n",
    "json.dump(list(extra_words),file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8917fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unicyclist', 'network-tv', 'porn-store', ''thank', 'bejewel', '¡que',\n",
       "       ''1989', 'grease-covered', 'once-homeless', 'cheese-related',\n",
       "       ...\n",
       "       ''least', 'love-tester', '.00003', ''build', 'helmet-inspired', 'jlaw',\n",
       "       ''justice', ''life-changer', ''gobble', ''wipe'],\n",
       "      dtype='object', length=4205)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f80f989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_final.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7d9d590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_final.update({len(vocab_final)+i-1:word for i,word in enumerate(extra_words)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a3b09a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "chec=set(list(vocab_final.keys()))\n",
    "chec2=set(range(404204))\n",
    "print(len(chec-chec2))\n",
    "print(len(chec2-chec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "32f7fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"vocab_final.json\",\"w\")\n",
    "json.dump(vocab_final,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1387ee29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'major'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(vocab_final)[224]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5182e9c",
   "metadata": {},
   "source": [
    "**Please Note**\n",
    "My Computing Resources were not enough to run through the entire corpus. I have to cut short after hours and hours of processing. So, came up with this idea of only first 1500 data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4a2c70",
   "metadata": {},
   "source": [
    "# End of Chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0fd74f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"data_ready.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "91c07d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json(\"data_vector.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "773a3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.DataFrame(df[\"headline\"].tolist(),index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a67140b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former</td>\n",
       "      <td>versace</td>\n",
       "      <td>store</td>\n",
       "      <td>clerk</td>\n",
       "      <td>sue</td>\n",
       "      <td>secret</td>\n",
       "      <td>'black</td>\n",
       "      <td>code</td>\n",
       "      <td>minority</td>\n",
       "      <td>shopper</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'roseanne</td>\n",
       "      <td>revival</td>\n",
       "      <td>catch</td>\n",
       "      <td>thorny</td>\n",
       "      <td>political</td>\n",
       "      <td>mood</td>\n",
       "      <td>better</td>\n",
       "      <td>worse</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom</td>\n",
       "      <td>starting</td>\n",
       "      <td>fear</td>\n",
       "      <td>son</td>\n",
       "      <td>'s</td>\n",
       "      <td>web</td>\n",
       "      <td>series</td>\n",
       "      <td>closest</td>\n",
       "      <td>thing</td>\n",
       "      <td>grandchild</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner</td>\n",
       "      <td>want</td>\n",
       "      <td>wife</td>\n",
       "      <td>listen</td>\n",
       "      <td>come</td>\n",
       "      <td>alternative</td>\n",
       "      <td>debt-reduction</td>\n",
       "      <td>idea</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k.</td>\n",
       "      <td>rowling</td>\n",
       "      <td>wish</td>\n",
       "      <td>snape</td>\n",
       "      <td>happy</td>\n",
       "      <td>birthday</td>\n",
       "      <td>magical</td>\n",
       "      <td>way</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26704</th>\n",
       "      <td>american</td>\n",
       "      <td>politics</td>\n",
       "      <td>moral</td>\n",
       "      <td>free-fall</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26705</th>\n",
       "      <td>america</td>\n",
       "      <td>'s</td>\n",
       "      <td>best</td>\n",
       "      <td>hike</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26706</th>\n",
       "      <td>reparation</td>\n",
       "      <td>obama</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26707</th>\n",
       "      <td>israeli</td>\n",
       "      <td>ban</td>\n",
       "      <td>targeting</td>\n",
       "      <td>boycott</td>\n",
       "      <td>supporter</td>\n",
       "      <td>raise</td>\n",
       "      <td>alarm</td>\n",
       "      <td>abroad</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26708</th>\n",
       "      <td>gourmet</td>\n",
       "      <td>gift</td>\n",
       "      <td>foodie</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26709 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1          2          3          4            5   \\\n",
       "0          former   versace      store      clerk        sue       secret   \n",
       "1       'roseanne   revival      catch     thorny  political         mood   \n",
       "2             mom  starting       fear        son         's          web   \n",
       "3         boehner      want       wife     listen       come  alternative   \n",
       "4            j.k.   rowling       wish      snape      happy     birthday   \n",
       "...           ...       ...        ...        ...        ...          ...   \n",
       "26704    american  politics      moral  free-fall       None         None   \n",
       "26705     america        's       best       hike       None         None   \n",
       "26706  reparation     obama       None       None       None         None   \n",
       "26707     israeli       ban  targeting    boycott  supporter        raise   \n",
       "26708     gourmet      gift     foodie       None       None         None   \n",
       "\n",
       "                   6        7         8           9   ...    17    18    19  \\\n",
       "0              'black     code  minority     shopper  ...  None  None  None   \n",
       "1              better    worse      None        None  ...  None  None  None   \n",
       "2              series  closest     thing  grandchild  ...  None  None  None   \n",
       "3      debt-reduction     idea      None        None  ...  None  None  None   \n",
       "4             magical      way      None        None  ...  None  None  None   \n",
       "...               ...      ...       ...         ...  ...   ...   ...   ...   \n",
       "26704            None     None      None        None  ...  None  None  None   \n",
       "26705            None     None      None        None  ...  None  None  None   \n",
       "26706            None     None      None        None  ...  None  None  None   \n",
       "26707           alarm   abroad      None        None  ...  None  None  None   \n",
       "26708            None     None      None        None  ...  None  None  None   \n",
       "\n",
       "         20    21    22    23    24    25    26  \n",
       "0      None  None  None  None  None  None  None  \n",
       "1      None  None  None  None  None  None  None  \n",
       "2      None  None  None  None  None  None  None  \n",
       "3      None  None  None  None  None  None  None  \n",
       "4      None  None  None  None  None  None  None  \n",
       "...     ...   ...   ...   ...   ...   ...   ...  \n",
       "26704  None  None  None  None  None  None  None  \n",
       "26705  None  None  None  None  None  None  None  \n",
       "26706  None  None  None  None  None  None  None  \n",
       "26707  None  None  None  None  None  None  None  \n",
       "26708  None  None  None  None  None  None  None  \n",
       "\n",
       "[26709 rows x 27 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98bb8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb7d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2[\"new_headline\"]=df2[\"headline\"].apply(word_tokens,vocab_final=vocab_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab04e1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50647fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(word_index_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e323eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(word_index_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_index_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b98a77bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_index_rev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-1a09cd1ee3f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_index_rev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'word_index_rev' is not defined"
     ]
    }
   ],
   "source": [
    "word_index_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c9bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe77f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=df3[:10000].replace(to_replace=word_index_rev) #just a check how it is working out\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f36af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "l+=1\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e49fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "df3=pd.DataFrame(pad_sequences(df3[\"headline\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc3a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"df3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf3c2f5",
   "metadata": {},
   "source": [
    "If we recall, we can go back and check that we already have a dataframe that is filled with word vectors for all 40000 of our words. So, we can go back and create a new dataframe with the newly created words that is named earlier as extra_words and make into a dataframe that is exactly matching with dimensions of our original dataframe so that our corpus is ready to be trained on pre-embeddings with new words added to the corpus, so that we can better detect sarcasm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ade039a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.038194</td>\n",
       "      <td>-0.24487</td>\n",
       "      <td>0.72812</td>\n",
       "      <td>-0.39961</td>\n",
       "      <td>0.083172</td>\n",
       "      <td>0.043953</td>\n",
       "      <td>-0.39141</td>\n",
       "      <td>0.3344</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>0.087459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016215</td>\n",
       "      <td>-0.017099</td>\n",
       "      <td>-0.38984</td>\n",
       "      <td>0.87424</td>\n",
       "      <td>-0.72569</td>\n",
       "      <td>-0.51058</td>\n",
       "      <td>-0.52028</td>\n",
       "      <td>-0.1459</td>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.27062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-0.10767</td>\n",
       "      <td>0.11053</td>\n",
       "      <td>0.59812</td>\n",
       "      <td>-0.54361</td>\n",
       "      <td>0.67396</td>\n",
       "      <td>0.10663</td>\n",
       "      <td>0.038867</td>\n",
       "      <td>0.35481</td>\n",
       "      <td>0.06351</td>\n",
       "      <td>-0.094189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.34951</td>\n",
       "      <td>-0.7226</td>\n",
       "      <td>0.37549</td>\n",
       "      <td>0.4441</td>\n",
       "      <td>-0.99059</td>\n",
       "      <td>0.61214</td>\n",
       "      <td>-0.35111</td>\n",
       "      <td>-0.83155</td>\n",
       "      <td>0.45293</td>\n",
       "      <td>0.082577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>-0.33979</td>\n",
       "      <td>0.20941</td>\n",
       "      <td>0.46348</td>\n",
       "      <td>-0.64792</td>\n",
       "      <td>-0.38377</td>\n",
       "      <td>0.038034</td>\n",
       "      <td>0.17127</td>\n",
       "      <td>0.15978</td>\n",
       "      <td>0.46619</td>\n",
       "      <td>-0.019169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063351</td>\n",
       "      <td>-0.67412</td>\n",
       "      <td>-0.068895</td>\n",
       "      <td>0.53604</td>\n",
       "      <td>-0.87773</td>\n",
       "      <td>0.31802</td>\n",
       "      <td>-0.39242</td>\n",
       "      <td>-0.23394</td>\n",
       "      <td>0.47298</td>\n",
       "      <td>-0.028803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-0.1529</td>\n",
       "      <td>-0.24279</td>\n",
       "      <td>0.89837</td>\n",
       "      <td>0.16996</td>\n",
       "      <td>0.53516</td>\n",
       "      <td>0.48784</td>\n",
       "      <td>-0.58826</td>\n",
       "      <td>-0.17982</td>\n",
       "      <td>-1.3581</td>\n",
       "      <td>0.42541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18712</td>\n",
       "      <td>-0.018488</td>\n",
       "      <td>-0.26757</td>\n",
       "      <td>0.727</td>\n",
       "      <td>-0.59363</td>\n",
       "      <td>-0.34839</td>\n",
       "      <td>-0.56094</td>\n",
       "      <td>-0.591</td>\n",
       "      <td>1.0039</td>\n",
       "      <td>0.20664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>-0.1897</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>0.19084</td>\n",
       "      <td>-0.049184</td>\n",
       "      <td>-0.089737</td>\n",
       "      <td>0.21006</td>\n",
       "      <td>-0.54952</td>\n",
       "      <td>0.098377</td>\n",
       "      <td>-0.20135</td>\n",
       "      <td>0.34241</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.13134</td>\n",
       "      <td>0.058617</td>\n",
       "      <td>-0.31869</td>\n",
       "      <td>-0.61419</td>\n",
       "      <td>-0.62393</td>\n",
       "      <td>-0.41548</td>\n",
       "      <td>-0.038175</td>\n",
       "      <td>-0.39804</td>\n",
       "      <td>0.47647</td>\n",
       "      <td>-0.15983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chanty</th>\n",
       "      <td>-0.15577</td>\n",
       "      <td>-0.049188</td>\n",
       "      <td>-0.064377</td>\n",
       "      <td>0.2236</td>\n",
       "      <td>-0.20146</td>\n",
       "      <td>-0.038963</td>\n",
       "      <td>0.12971</td>\n",
       "      <td>-0.29451</td>\n",
       "      <td>0.0035897</td>\n",
       "      <td>-0.098377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093324</td>\n",
       "      <td>0.094486</td>\n",
       "      <td>-0.023469</td>\n",
       "      <td>-0.48099</td>\n",
       "      <td>0.62332</td>\n",
       "      <td>0.024318</td>\n",
       "      <td>-0.27587</td>\n",
       "      <td>0.075044</td>\n",
       "      <td>-0.5638</td>\n",
       "      <td>0.14501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kronik</th>\n",
       "      <td>-0.094426</td>\n",
       "      <td>0.14725</td>\n",
       "      <td>-0.15739</td>\n",
       "      <td>0.071966</td>\n",
       "      <td>-0.29845</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>0.02187</td>\n",
       "      <td>0.0080409</td>\n",
       "      <td>-0.18682</td>\n",
       "      <td>-0.31101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.30545</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>0.11855</td>\n",
       "      <td>-0.11312</td>\n",
       "      <td>0.33951</td>\n",
       "      <td>-0.22449</td>\n",
       "      <td>0.25743</td>\n",
       "      <td>0.63143</td>\n",
       "      <td>-0.2009</td>\n",
       "      <td>-0.10542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rolonda</th>\n",
       "      <td>0.36088</td>\n",
       "      <td>-0.16919</td>\n",
       "      <td>-0.32704</td>\n",
       "      <td>0.098332</td>\n",
       "      <td>-0.4297</td>\n",
       "      <td>-0.18874</td>\n",
       "      <td>0.45556</td>\n",
       "      <td>0.28529</td>\n",
       "      <td>0.3034</td>\n",
       "      <td>-0.36683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044082</td>\n",
       "      <td>0.14003</td>\n",
       "      <td>0.30007</td>\n",
       "      <td>-0.12731</td>\n",
       "      <td>-0.14304</td>\n",
       "      <td>-0.069396</td>\n",
       "      <td>0.2816</td>\n",
       "      <td>0.27139</td>\n",
       "      <td>-0.29188</td>\n",
       "      <td>0.16109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zsombor</th>\n",
       "      <td>-0.10461</td>\n",
       "      <td>-0.5047</td>\n",
       "      <td>-0.49331</td>\n",
       "      <td>0.13516</td>\n",
       "      <td>-0.36371</td>\n",
       "      <td>-0.4475</td>\n",
       "      <td>0.18429</td>\n",
       "      <td>-0.05651</td>\n",
       "      <td>0.40474</td>\n",
       "      <td>-0.72583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15153</td>\n",
       "      <td>-0.10842</td>\n",
       "      <td>0.34064</td>\n",
       "      <td>-0.40916</td>\n",
       "      <td>-0.081263</td>\n",
       "      <td>0.095315</td>\n",
       "      <td>0.15018</td>\n",
       "      <td>0.42527</td>\n",
       "      <td>-0.5125</td>\n",
       "      <td>-0.17054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sandberger</th>\n",
       "      <td>0.28365</td>\n",
       "      <td>-0.6263</td>\n",
       "      <td>-0.44351</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>-0.087421</td>\n",
       "      <td>-0.17062</td>\n",
       "      <td>0.29266</td>\n",
       "      <td>-0.024899</td>\n",
       "      <td>0.26414</td>\n",
       "      <td>-0.17023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13885</td>\n",
       "      <td>-0.22862</td>\n",
       "      <td>0.071792</td>\n",
       "      <td>-0.43208</td>\n",
       "      <td>0.5398</td>\n",
       "      <td>-0.085806</td>\n",
       "      <td>0.032651</td>\n",
       "      <td>0.43678</td>\n",
       "      <td>-0.82607</td>\n",
       "      <td>-0.15701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1          2          3          4          5   \\\n",
       "word                                                                           \n",
       "the         -0.038194   -0.24487    0.72812   -0.39961   0.083172   0.043953   \n",
       ",            -0.10767    0.11053    0.59812   -0.54361    0.67396    0.10663   \n",
       ".            -0.33979    0.20941    0.46348   -0.64792   -0.38377   0.038034   \n",
       "of            -0.1529   -0.24279    0.89837    0.16996    0.53516    0.48784   \n",
       "to            -0.1897   0.050024    0.19084  -0.049184  -0.089737    0.21006   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "chanty       -0.15577  -0.049188  -0.064377     0.2236   -0.20146  -0.038963   \n",
       "kronik      -0.094426    0.14725   -0.15739   0.071966   -0.29845   0.039432   \n",
       "rolonda       0.36088   -0.16919   -0.32704   0.098332    -0.4297   -0.18874   \n",
       "zsombor      -0.10461    -0.5047   -0.49331    0.13516   -0.36371    -0.4475   \n",
       "sandberger    0.28365    -0.6263   -0.44351     0.2177  -0.087421   -0.17062   \n",
       "\n",
       "                  6          7          8          9   ...         90  \\\n",
       "word                                                   ...              \n",
       "the         -0.39141     0.3344   -0.57545   0.087459  ...   0.016215   \n",
       ",           0.038867    0.35481    0.06351  -0.094189  ...    0.34951   \n",
       ".            0.17127    0.15978    0.46619  -0.019169  ...  -0.063351   \n",
       "of          -0.58826   -0.17982    -1.3581    0.42541  ...    0.18712   \n",
       "to          -0.54952   0.098377   -0.20135    0.34241  ...   -0.13134   \n",
       "...              ...        ...        ...        ...  ...        ...   \n",
       "chanty       0.12971   -0.29451  0.0035897  -0.098377  ...   0.093324   \n",
       "kronik       0.02187  0.0080409   -0.18682   -0.31101  ...   -0.30545   \n",
       "rolonda      0.45556    0.28529     0.3034   -0.36683  ...  -0.044082   \n",
       "zsombor      0.18429   -0.05651    0.40474   -0.72583  ...    0.15153   \n",
       "sandberger   0.29266  -0.024899    0.26414   -0.17023  ...    0.13885   \n",
       "\n",
       "                   91         92        93         94         95         96  \\\n",
       "word                                                                          \n",
       "the         -0.017099   -0.38984   0.87424   -0.72569   -0.51058   -0.52028   \n",
       ",             -0.7226    0.37549    0.4441   -0.99059    0.61214   -0.35111   \n",
       ".            -0.67412  -0.068895   0.53604   -0.87773    0.31802   -0.39242   \n",
       "of          -0.018488   -0.26757     0.727   -0.59363   -0.34839   -0.56094   \n",
       "to           0.058617   -0.31869  -0.61419   -0.62393   -0.41548  -0.038175   \n",
       "...               ...        ...       ...        ...        ...        ...   \n",
       "chanty       0.094486  -0.023469  -0.48099    0.62332   0.024318   -0.27587   \n",
       "kronik      -0.011082    0.11855  -0.11312    0.33951   -0.22449    0.25743   \n",
       "rolonda       0.14003    0.30007  -0.12731   -0.14304  -0.069396     0.2816   \n",
       "zsombor      -0.10842    0.34064  -0.40916  -0.081263   0.095315    0.15018   \n",
       "sandberger   -0.22862   0.071792  -0.43208     0.5398  -0.085806   0.032651   \n",
       "\n",
       "                  97        98         99  \n",
       "word                                       \n",
       "the          -0.1459    0.8278    0.27062  \n",
       ",           -0.83155   0.45293   0.082577  \n",
       ".           -0.23394   0.47298  -0.028803  \n",
       "of            -0.591    1.0039    0.20664  \n",
       "to          -0.39804   0.47647   -0.15983  \n",
       "...              ...       ...        ...  \n",
       "chanty      0.075044   -0.5638    0.14501  \n",
       "kronik       0.63143   -0.2009   -0.10542  \n",
       "rolonda      0.27139  -0.29188    0.16109  \n",
       "zsombor      0.42527   -0.5125   -0.17054  \n",
       "sandberger   0.43678  -0.82607   -0.15701  \n",
       "\n",
       "[400000 rows x 100 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8345bfc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toll-booth</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emojisinthewild</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'bet</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'very</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'share</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nidetch</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy-grip</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'sweetie</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'bring</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38-year-olds</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4205 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0   1   2   3   4   5   6   7   8   9   ...  90  91  92  93  \\\n",
       "toll-booth        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   \n",
       "emojisinthewild   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   \n",
       "'bet              0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   \n",
       "'very             0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   \n",
       "'share            0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   \n",
       "...              ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..   \n",
       "nidetch           0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   \n",
       "easy-grip         0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   \n",
       "'sweetie          0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   \n",
       "'bring            0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   \n",
       "38-year-olds      0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   \n",
       "\n",
       "                 94  95  96  97  98  99  \n",
       "toll-booth        0   0   0   0   0   0  \n",
       "emojisinthewild   0   0   0   0   0   0  \n",
       "'bet              0   0   0   0   0   0  \n",
       "'very             0   0   0   0   0   0  \n",
       "'share            0   0   0   0   0   0  \n",
       "...              ..  ..  ..  ..  ..  ..  \n",
       "nidetch           0   0   0   0   0   0  \n",
       "easy-grip         0   0   0   0   0   0  \n",
       "'sweetie          0   0   0   0   0   0  \n",
       "'bring            0   0   0   0   0   0  \n",
       "38-year-olds      0   0   0   0   0   0  \n",
       "\n",
       "[4205 rows x 100 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_append=pd.DataFrame(0,index=extra_words,columns=range(100))\n",
    "to_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f51173d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([data,to_append]) #This is our final dataframe that we are going to convert to a word_index for pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1cfd32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new=data.drop(irrelevant_words,axis=0).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c00986",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "Now we can go ahead and try to eliminate more than half of words that don't occur at all in our given corpus. It is pretty easy and would probably save a lot on our computational complexity. However, I am going to give it a chance, keep it as it is, in the hopes to use it in future sometime, or perhaps adding in more data for other purposes.\n",
    "\n",
    "But for this specific problem, I am going to drop it.\n",
    "\n",
    "There are not hits and misses here. There is a room for a LOTS of improvement and optimization here. But due to time complexity involved, it is being ignored here and I am going with it like that here because I am only using a part of the dataframe i.e. just 1500 data points from the given corpus because of the computational complexity involved.\n",
    "\n",
    "But before that let us save the data lest, we loose it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9aa5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.to_json(\"Final_table.json\",index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf449cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"df2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cbdb3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new=data_new.reset_index().drop([\"index\"],axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0497e28",
   "metadata": {},
   "source": [
    "## Model Layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1884d1",
   "metadata": {},
   "source": [
    "**Note** : I deliberately choose small and simple model for the sake of training and everything. Please be considerate on that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
