{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c9790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't Run this Cell. This is for parallel programming\n",
    "import ipyparallel as ipp\n",
    "import time\n",
    "\n",
    "c=ipp.Client()\n",
    "\n",
    "dview=c[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffecd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df2=pd.read_csv(\"Data Set - industrial_safety_and_health_database_with_accidents_description.csv\")\n",
    "\n",
    "df2.head()\n",
    "df2.drop(\"Unnamed: 0\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89543781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Local</th>\n",
       "      <th>Industry Sector</th>\n",
       "      <th>Accident Level</th>\n",
       "      <th>Potential Accident Level</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Employee or Third Party</th>\n",
       "      <th>Critical Risk</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>Country_01</td>\n",
       "      <td>Local_01</td>\n",
       "      <td>Mining</td>\n",
       "      <td>I</td>\n",
       "      <td>IV</td>\n",
       "      <td>Male</td>\n",
       "      <td>Third Party</td>\n",
       "      <td>Pressed</td>\n",
       "      <td>While removing the drill rod of the Jumbo 08 f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02 00:00:00</td>\n",
       "      <td>Country_02</td>\n",
       "      <td>Local_02</td>\n",
       "      <td>Mining</td>\n",
       "      <td>I</td>\n",
       "      <td>IV</td>\n",
       "      <td>Male</td>\n",
       "      <td>Employee</td>\n",
       "      <td>Pressurized Systems</td>\n",
       "      <td>During the activation of a sodium sulphide pum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06 00:00:00</td>\n",
       "      <td>Country_01</td>\n",
       "      <td>Local_03</td>\n",
       "      <td>Mining</td>\n",
       "      <td>I</td>\n",
       "      <td>III</td>\n",
       "      <td>Male</td>\n",
       "      <td>Third Party (Remote)</td>\n",
       "      <td>Manual Tools</td>\n",
       "      <td>In the sub-station MILPO located at level +170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-08 00:00:00</td>\n",
       "      <td>Country_01</td>\n",
       "      <td>Local_04</td>\n",
       "      <td>Mining</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>Male</td>\n",
       "      <td>Third Party</td>\n",
       "      <td>Others</td>\n",
       "      <td>Being 9:45 am. approximately in the Nv. 1880 C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-10 00:00:00</td>\n",
       "      <td>Country_01</td>\n",
       "      <td>Local_04</td>\n",
       "      <td>Mining</td>\n",
       "      <td>IV</td>\n",
       "      <td>IV</td>\n",
       "      <td>Male</td>\n",
       "      <td>Third Party</td>\n",
       "      <td>Others</td>\n",
       "      <td>Approximately at 11:45 a.m. in circumstances t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Data   Countries     Local Industry Sector Accident Level  \\\n",
       "0  2016-01-01 00:00:00  Country_01  Local_01          Mining              I   \n",
       "1  2016-01-02 00:00:00  Country_02  Local_02          Mining              I   \n",
       "2  2016-01-06 00:00:00  Country_01  Local_03          Mining              I   \n",
       "3  2016-01-08 00:00:00  Country_01  Local_04          Mining              I   \n",
       "4  2016-01-10 00:00:00  Country_01  Local_04          Mining             IV   \n",
       "\n",
       "  Potential Accident Level Genre Employee or Third Party        Critical Risk  \\\n",
       "0                       IV  Male             Third Party              Pressed   \n",
       "1                       IV  Male                Employee  Pressurized Systems   \n",
       "2                      III  Male    Third Party (Remote)         Manual Tools   \n",
       "3                        I  Male             Third Party               Others   \n",
       "4                       IV  Male             Third Party               Others   \n",
       "\n",
       "                                         Description  \n",
       "0  While removing the drill rod of the Jumbo 08 f...  \n",
       "1  During the activation of a sodium sulphide pum...  \n",
       "2  In the sub-station MILPO located at level +170...  \n",
       "3  Being 9:45 am. approximately in the Nv. 1880 C...  \n",
       "4  Approximately at 11:45 a.m. in circumstances t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268cf0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df2[[\"Accident Level\",\"Description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa1ddb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=[\"Target\",\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69b51496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Target\"]=df[\"Target\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "194e1e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>While removing the drill rod of the Jumbo 08 f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>During the activation of a sodium sulphide pum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>In the sub-station MILPO located at level +170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>Being 9:45 am. approximately in the Nv. 1880 C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IV</td>\n",
       "      <td>Approximately at 11:45 a.m. in circumstances t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>I</td>\n",
       "      <td>Being approximately 5:00 a.m. approximately, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>I</td>\n",
       "      <td>The collaborator moved from the infrastructure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>I</td>\n",
       "      <td>During the environmental monitoring activity i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>I</td>\n",
       "      <td>The Employee performed the activity of strippi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>I</td>\n",
       "      <td>At 10:00 a.m., when the assistant cleaned the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Target                                               Text\n",
       "0        I  While removing the drill rod of the Jumbo 08 f...\n",
       "1        I  During the activation of a sodium sulphide pum...\n",
       "2        I  In the sub-station MILPO located at level +170...\n",
       "3        I  Being 9:45 am. approximately in the Nv. 1880 C...\n",
       "4       IV  Approximately at 11:45 a.m. in circumstances t...\n",
       "..     ...                                                ...\n",
       "420      I  Being approximately 5:00 a.m. approximately, w...\n",
       "421      I  The collaborator moved from the infrastructure...\n",
       "422      I  During the environmental monitoring activity i...\n",
       "423      I  The Employee performed the activity of strippi...\n",
       "424      I  At 10:00 a.m., when the assistant cleaned the ...\n",
       "\n",
       "[425 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cdfd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "#########################################################\n",
    "# Eliminating date and time entry strings\n",
    "#########################################################\n",
    "def is_date(string, fuzzy=False):\n",
    "    try: \n",
    "        parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "#########################################################\n",
    "# Function giving us cleaned word tokens\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7e59d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sheshank_Joshi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "#########################################################\n",
    "# Function giving us cleaned word tokens\n",
    "#########################################################\n",
    "def word_processing(text_input):\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords=stopwords.words('english')\n",
    "    import string\n",
    "    from dateutil.parser import parse\n",
    "    from string import punctuation as punct\n",
    "    ###################################################\n",
    "    def is_date(string, fuzzy=False):\n",
    "        try: \n",
    "            parse(string, fuzzy=fuzzy)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "    ##################################################\n",
    "    from nltk.corpus import words as eng_words\n",
    "    text=word_tokenize(text_input)\n",
    "    text=[word.lower() for word in text if word not in stopwords]\n",
    "    text=[word for word in text if word not in punct]\n",
    "    text=[word for word in text if not is_date(word)]\n",
    "    text=[word for word in text if word in eng_words.words()]\n",
    "    return text\n",
    "######################################################\n",
    "# End of Function\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d0c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=df[\"Text\"][1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "486b73cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Must be a dict, not <class 'function'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ea5bfd34c9d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipyparallel\\client\\view.py\u001b[0m in \u001b[0;36mpush\u001b[1;34m(self, ns, targets, block, track)\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[1;31m# applier = self.apply_sync if block else self.apply_async\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Must be a dict, not %s\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_really_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_push\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Must be a dict, not <class 'function'>"
     ]
    }
   ],
   "source": [
    "dview.push(is_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f9eb962",
   "metadata": {},
   "outputs": [
    {
     "ename": "CompositeError",
     "evalue": "one or more exceptions from call to method: word_processing\n[0:apply]: NameError: name 'is_date' is not defined\n[1:apply]: NameError: name 'is_date' is not defined\n[2:apply]: NameError: name 'is_date' is not defined\n[3:apply]: NameError: name 'is_date' is not defined\n.... 2 more exceptions ...",
     "output_type": "error",
     "traceback": [
      "[0:apply]: ",
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipyparallel\\client\\remotefunction.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *sequences)\u001b[0m",
      "\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[0;32m    142\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[1;32m--> 143\u001b[1;33m     \u001b[0m_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[0;32m    145\u001b[0m     \u001b[0m_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[1;32m<ipython-input-13-da134fffe0d4>\u001b[0m in \u001b[0;36mword_processing\u001b[1;34m(text_input)\u001b[0m",
      "\u001b[1;32m<ipython-input-13-da134fffe0d4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'is_date' is not defined",
      "",
      "[1:apply]: ",
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipyparallel\\client\\remotefunction.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *sequences)\u001b[0m",
      "\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[0;32m    142\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[1;32m--> 143\u001b[1;33m     \u001b[0m_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[0;32m    145\u001b[0m     \u001b[0m_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[1;32m<ipython-input-13-da134fffe0d4>\u001b[0m in \u001b[0;36mword_processing\u001b[1;34m(text_input)\u001b[0m",
      "\u001b[1;32m<ipython-input-13-da134fffe0d4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'is_date' is not defined",
      "",
      "[2:apply]: ",
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipyparallel\\client\\remotefunction.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *sequences)\u001b[0m",
      "\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[0;32m    142\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[1;32m--> 143\u001b[1;33m     \u001b[0m_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[0;32m    145\u001b[0m     \u001b[0m_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[1;32m<ipython-input-13-da134fffe0d4>\u001b[0m in \u001b[0;36mword_processing\u001b[1;34m(text_input)\u001b[0m",
      "\u001b[1;32m<ipython-input-13-da134fffe0d4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'is_date' is not defined",
      "",
      "[3:apply]: ",
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipyparallel\\client\\remotefunction.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *sequences)\u001b[0m",
      "\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[0;32m    142\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[1;32m--> 143\u001b[1;33m     \u001b[0m_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[0;32m    145\u001b[0m     \u001b[0m_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m",
      "\u001b[1;32m<ipython-input-13-da134fffe0d4>\u001b[0m in \u001b[0;36mword_processing\u001b[1;34m(text_input)\u001b[0m",
      "\u001b[1;32m<ipython-input-13-da134fffe0d4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'is_date' is not defined",
      "",
      "... 2 more exceptions ..."
     ]
    }
   ],
   "source": [
    "dview.map_sync(word_processing,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e610a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"]=df[\"Text\"].apply(word_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf08c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"count\"]=df[\"tokens\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f838108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "for each in stopwords.words(\"english\"):\n",
    "    #print(each)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21848ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dba9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"count\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4cf595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import ngrams, FreqDist\n",
    "from nltk.util import flatten\n",
    "from nltk import ngrams\n",
    "from nltk.util import skipgrams\n",
    "from nltk.util import trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2aa868",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text=[]\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "for tokens in df[\"tokens\"]:  \n",
    "    #\n",
    "    lemmatized_words=[lemmatizer.lemmatize(word) for word in tokens if not word.isdigit()]\n",
    "    #\n",
    "    stemmed_tokens=[stemmer.stem(word) for word in lemmatized_words]\n",
    "    processed_text.append(stemmed_tokens)\n",
    "\n",
    "df[\"tokens\"]=processed_text\n",
    "df[\"count\"]=df[\"tokens\"].apply(len)\n",
    "#word_frequency=FreqDist(flatten(processed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a45328",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_corpus=pd.Series(FreqDist(flatten(list(df[\"tokens\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f43a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_corpus.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4e316a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df[\"tokens\"][0] #Unprocessed Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eefc83b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#processed_text[0] # Processed Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76544df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bigrams_present=list(ngrams(flatten(list(df[\"tokens\"])),2))\n",
    "trigrams_present=list(ngrams(flatten(list(df[\"tokens\"])),3))\n",
    "skipgrams_present=list(skipgrams(flatten(list(df[\"tokens\"])),2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c39e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211538ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipgrams_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e8f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FreqDist(bigrams_present) # This presents a very interesting perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e3156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FreqDist(trigrams_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c228ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FreqDist(skipgrams_present)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22db76e",
   "metadata": {},
   "source": [
    "Keeping only top 5 bigrams and top 5 trigrams here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a22949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Function giving us the actual bigrams\n",
    "#########################################################\n",
    "def extract_ngrams(data):\n",
    "    out=[]\n",
    "    for i in range(len(data)):\n",
    "        out.append(data[i][0])\n",
    "    return out\n",
    "#########################################################\n",
    "# End of Function\n",
    "#########################################################    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7777d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Function giving us the bigram distribution across the data table\n",
    "#########################################################\n",
    "\n",
    "def ngram_df(dataframe_tokens,no,skip=False):\n",
    "    df=dataframe_tokens\n",
    "    if skip:\n",
    "        k=df.apply(skipgrams,k=3,n=no).apply(list) # Here \"k\" can be changed and shifted\n",
    "        n_gram=skipgram_data\n",
    "    else:\n",
    "        k=df.apply(ngrams,n=no).apply(list)\n",
    "        if no==2:\n",
    "            n_gram=bigram_data\n",
    "        else:\n",
    "            n_gram=trigram_data\n",
    "    master_data=[]\n",
    "    for each in k:\n",
    "        bi_list=[]\n",
    "        for i in range(len(bigram_data)):\n",
    "            bi_list.append(each.count(n_gram[i]))\n",
    "        #print(bigram_data[0])\n",
    "        #print(bi_list)\n",
    "        try:\n",
    "            master_data.append(bi_list)\n",
    "        except:\n",
    "            pass\n",
    "    return pd.DataFrame(master_data,columns=n_gram)\n",
    "#########################################################\n",
    "# End of Function\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f835d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_ngram=5\n",
    "\n",
    "whole_corpus = FreqDist(flatten())\n",
    "\n",
    "bigram_data = extract_ngrams(FreqDist(bigrams_present).most_common(no_of_ngram))\n",
    "trigram_data = extract_ngrams(FreqDist(trigrams_present).most_common(no_of_ngram))\n",
    "skipgram_data = extract_ngrams(FreqDist(skipgrams_present).most_common(no_of_ngram))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe169360",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e048ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigram=ngram_df(df[\"tokens\"],no=2)\n",
    "df_trigram=ngram_df(df[\"tokens\"],no=3)\n",
    "df_skipgram=ngram_df(df[\"tokens\"],2,skip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde89685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skipgram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb625c",
   "metadata": {},
   "source": [
    "These are the bigram, tri-gram and skip gram encodings of the text, to be loaded for further analysis, for indicators of the fields of deciding what to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850cc6ec",
   "metadata": {},
   "source": [
    "## Analysis for bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ef2a2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bigram=df.join([df_bigram,df2[[\"Accident Level\",\"Potential Accident Level\",\"Industry Sector\",\"Critical Risk\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3081f9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf8cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now grouping based on the how these bigrams are distributed.\n",
    "cat=df_bigram.groupby(\"Accident Level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb650f",
   "metadata": {},
   "source": [
    "**Task**\n",
    "Depending upon which grams is giving maximum correlation with the type of industry and also the type of disaster at hand, we can choose to retain those ngrams or just leave them. It all depends. So, think about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb63ab3",
   "metadata": {},
   "source": [
    "### For Level 1 Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf446ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1=cat.get_group(\"I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc62313",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.heatmap(cat1.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc2b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=cat1.iloc[:,4:9]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.sum() # The number of occurrences in this category "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817c22c0",
   "metadata": {},
   "source": [
    "### For Level 2 Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6fe76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cat2=cat.get_group(\"II\")\n",
    "sns.heatmap(cat2.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213171c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp=cat2.iloc[:,4:9]\n",
    "temp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c92bfe",
   "metadata": {},
   "source": [
    "### For Level 3 Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28569432",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat3=cat.get_group(\"III\")\n",
    "sns.heatmap(cat3.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c502a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=cat3.iloc[:,4:9]\n",
    "temp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d47b217",
   "metadata": {},
   "source": [
    "### For Level 4 Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7fdd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat4=cat.get_group(\"IV\")\n",
    "sns.heatmap(cat4.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd26ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=cat4.iloc[:,4:9]\n",
    "temp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b350c52c",
   "metadata": {},
   "source": [
    "### For Level 5 Reporting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ba4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat5=cat.get_group(\"IV\")\n",
    "sns.heatmap(cat5.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2543a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=cat5.iloc[:,4:9]\n",
    "temp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02519e",
   "metadata": {},
   "source": [
    "**Important Observation**\n",
    "\n",
    "\n",
    "Whenver the word \"left hand\" is used, it is highly likely that it is going to escalate into higher and higher levels of potential. That means, if those words every come into description, we have to be extra careful with it. \n",
    "\n",
    "Also if the time of the accident is perfectly given by time, accident bigrams that means the accident is very well noted down and less chance of esacalating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d201d",
   "metadata": {},
   "source": [
    "## Analysis of Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ea18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trigram=df.join([df_trigram,df2[[\"Accident Level\",\"Potential Accident Level\",\"Industry Sector\",\"Critical Risk\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea17babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.histplot(data=cat3,x=\"Industry Sector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439842d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77de665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now grouping based on the how these bigrams are distributed.\n",
    "cat=df_trigram.groupby(\"Accident Level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236224cb",
   "metadata": {},
   "source": [
    "### For Level 1 Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef91f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat1=cat.get_group(\"I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad3da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cat1.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33148bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=cat1.iloc[:,4:9]\n",
    "temp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b1159",
   "metadata": {},
   "source": [
    "### For Level 2  Reporting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ab0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat2=cat.get_group(\"II\")\n",
    "sns.heatmap(cat5.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e806d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=cat2.iloc[:,4:9]\n",
    "temp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f1a14d",
   "metadata": {},
   "source": [
    "### For Level 3 Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310b0b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat3=cat.get_group(\"III\")\n",
    "sns.heatmap(cat3.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357fe1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=cat3.iloc[:,4:9]\n",
    "temp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df244141",
   "metadata": {},
   "source": [
    "### For Level 4 Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888665b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat4=cat.get_group(\"IV\")\n",
    "sns.heatmap(cat4.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb81b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=cat4.iloc[:,4:9]\n",
    "temp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbef2c7",
   "metadata": {},
   "source": [
    "### For Level 5 Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat5=cat.get_group(\"V\")\n",
    "sns.heatmap(cat5.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b1753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=cat5.iloc[:,4:9]\n",
    "temp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a1756d",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "It is observed here that there aren't many trigrams in use and hence don't indicate anything much about the possible data about prediction. Hence, trigrams aren't of much importance when dealing with data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ee511",
   "metadata": {},
   "source": [
    "## Analysis of Skipgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0466c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skipgram=df.join([df_skipgram,df2[[\"Accident Level\",\"Potential Accident Level\",\"Industry Sector\",\"Critical Risk\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d2263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_skipgram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08df23c3",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "It is observed that skipgrams share the same pairs as that of Bigrams. There is no point in repeating them. But, it needs to be investigated why they are the same. But, if they turn out to be same, it is most probably because the description of text is never beyond an average of 36 words to describe text. So, there is not much scope towards analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcce66b",
   "metadata": {},
   "source": [
    "## Conclusion Based on ngram, Skipgram Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9685c029",
   "metadata": {},
   "source": [
    "It can be seen that though bigrams are of much importance, tri grams don't seem to be of much influence. Skipgrams also don't seem to have that good of a analytic part too. There are two conclusions to make here.\n",
    "\n",
    "1. Enough analysis based on the separate sentence break down (sentence tokenization) needs to be done so that proper representation can be done whether the skipgrams were any effective in judging sequential relationship between data and its indicator of anyway between escalation of reported incident to higher incident.\n",
    "\n",
    "2. Most of the bigram combinations and the wrods listed in these ngrams occupy a major chunk of the given description of any incident. Hence, it becomes important that we have to have proper analysis of unique words in the corpus and possible relation to being in any particular Industry or sector. That way, we can make sure that we can compensate the corpus data that we have as description to fill up the data, if not given by the user.\n",
    "\n",
    "3. Given that above is not done, or if is deemed not required, we can proceed towards the suggestion that LSTM networks if used, doesn't need to process very or extremely long sequences. So, just two or 3 LSTM units are enough for the processing.\n",
    "\n",
    "4. If it is decided that to replace words with their bigram counter parts, then it is advised that one should implement a method to repeat the same in the input data at runtime, so appropriate care is taken.\n",
    "\n",
    "5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b831d3c",
   "metadata": {},
   "source": [
    "# Analysis of Word Frequencies with respect to each of the Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa30805e",
   "metadata": {},
   "source": [
    "## Analyzing by Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c8795",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df.join(df2[[\"Accident Level\",\"Potential Accident Level\",\"Industry Sector\",\"Critical Risk\"]]).groupby(\"Industry Sector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c191e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"Industry Sector\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c67e60",
   "metadata": {},
   "source": [
    "### Metals Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8012e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=df3.get_group(\"Metals\")\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=cat,x=cat[\"Accident Level\"],hue=\"Potential Accident Level\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c7d48",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "It is observed here that in Mining Industry Level 1 incident is quickly escalating to level 2, then to level 3 and so on. But, if the reported incident itself is starting at level 2, then there is little chance of sustaining it at level 2, it will equally likely to escalate into level 4 (even skipping level 3). \n",
    "\n",
    "Simiarly once observed at level 3 it is highly likely that it is not at all sustained at level 3. It will most likely go into level 4. \n",
    "\n",
    "But when it is observed to be at level 4 it will likely sustained at level 4 and will not move into level5. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f515b7",
   "metadata": {},
   "source": [
    "Based on the above data we are now going to get some word frequency predicitons and how they are distributed across the potential incident levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2eaa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_corpus.sort_values(ascending=False) # This is for the entire Corpus of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0aec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_metal=pd.Series(FreqDist(flatten(list(cat[\"tokens\"])))).sort_values(ascending=False)\n",
    "corp_metal[:10]\n",
    "#This is the Corpus of the Metal Industry for most used 10 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c9745",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "There seems to be a lot more left hand related accidents in metal industry than there are any other field.\n",
    "\n",
    "Most of the words that are in original corpus i.e. 50% of them, are in the corpus for Metal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5866574",
   "metadata": {},
   "source": [
    "### Mining Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=df3.get_group(\"Mining\")\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e255f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=cat,x=cat[\"Accident Level\"],hue=\"Potential Accident Level\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf822b",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "It seems that those that are reported at level 1 are more than likely to end up at level 4 potential. Very little portion of the level 1 incidents seem to be retained at that very same level.\n",
    "\n",
    "Extremely low number actually have the highest potential from level 4 disaster. \n",
    "\n",
    "There is always quick escalation from level 3 to level 4 and sustenance in level 3 is very little for Mining Industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27feec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_mining=pd.Series(FreqDist(flatten(list(cat[\"tokens\"])))).sort_values(ascending=False)\n",
    "corp_mining[:10]\n",
    "# This is the Corpus of the Mining Industry for most used 10 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a821d3b",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "*The MOST IMPORTANT OBSERVATION* here is that right hand seems to be involved a lot more in the incidents related to mining than for metals. This is a very important indicator for further analysis (especially to compensate for missing data).\n",
    "\n",
    "Most of the incidents seem to be that operation related incidents i.e. while working and not some other time. So, that is one thing we need to work out.\n",
    "\n",
    "Large number of words i.e. more than 1800 words are used in this corpus. That means the description for Mining is more varied than that of metals. Hence, we can think that if the description given is more scattered, especially the word vectors can't be clustered, then we can simply think that they are a particular kind.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b3038",
   "metadata": {},
   "source": [
    "# Others Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a2239",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=df3.get_group(\"Others\")\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ce256",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=cat,x=cat[\"Accident Level\"],hue=\"Potential Accident Level\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add60c80",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "For any reported incident of level 1 stayed in level 1 for other industries. That also means thatit doesn't escalate any further than that. It doesn't escalate to anything more than level 4.\n",
    "\n",
    "Those that are identified as level 2 stayed level 2 and those identified level 3 stayed level 3 (fore the most part) and those that are identified as level 4 has stayed level 4 and hasn't escalated any further in potential threat level.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85057e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_others=pd.Series(FreqDist(flatten(list(cat[\"tokens\"])))).sort_values(ascending=False)\n",
    "corp_others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc7093",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "Most of the time is the active employees that either observe or are somehow involved in the incidents.\n",
    "\n",
    "Since there are less than half number of words that are used in this category compared to the rest, we can be pretty sure that much lesser number of important or useful words are there in this.\n",
    "\n",
    "We can be pretty sure that if a certain number of words of certainly be absent, we can be sure that it is \"others\" category because presence of those words will more likely produce the \"Mining\" or \"Metal\" industry issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0929a",
   "metadata": {},
   "source": [
    "## Cross Analysis for Industries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(corp_others.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60bf44c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
