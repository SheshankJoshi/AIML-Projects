{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "voluntary-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Reshape\n",
    "from tensorflow.keras.layers import Concantenate()\n",
    "IMAGE_SIZE=128\n",
    "ALPHA = 1.0 # Width hyper parameter for MobileNet (0.25, 0.5, 0.75, 1.0). Higher width means more accurate but slower\n",
    "\n",
    "def create_model(trainable=True):\n",
    "    model = MobileNet(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, alpha=ALPHA) # Load pre-trained mobilenet\n",
    "    # Do not include classification (top) layer\n",
    "\n",
    "    # to freeze layers, except the new top layer, of course, which will be added below\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    # Add new top layer which is a conv layer of the same size as the previous layer so that only 4 coords of BBox can be output\n",
    "    x0 = model.layers[-1].output\n",
    "    x1 = Conv2D(4, kernel_size=4, name=\"coords\")(x0)\n",
    "    # In the line above kernel size should be 3 for img size 96, 4 for img size 128, 5 for img size 160 etc.\n",
    "    x2 = Reshape((4,))(x1) # These are the 4 predicted coordinates of one BBox\n",
    "\n",
    "    return Model(inputs=model.input, outputs=x2)\n",
    "\n",
    "def IOU(y_true, y_pred):\n",
    "    intersections = 0\n",
    "    unions = 0\n",
    "    # set the types so we are sure what type we are using\n",
    "\n",
    "    gt = y_true\n",
    "    pred = y_pred\n",
    "    # Compute interection of predicted (pred) and ground truth (gt) bounding boxes\n",
    "    diff_width = np.minimum(gt[:,0] + gt[:,2], pred[:,0] + pred[:,2]) - np.maximum(gt[:,0], pred[:,0])\n",
    "    diff_height = np.minimum(gt[:,1] + gt[:,3], pred[:,1] + pred[:,3]) - np.maximum(gt[:,1], pred[:,1])\n",
    "    intersection = diff_width * diff_height\n",
    "\n",
    "    # Compute union\n",
    "    area_gt = gt[:,2] * gt[:,3]\n",
    "    area_pred = pred[:,2] * pred[:,3]\n",
    "    union = area_gt + area_pred - intersection\n",
    "\n",
    "    # Compute intersection and union over multiple boxes\n",
    "    for j, _ in enumerate(union):\n",
    "      if union[j] > 0 and intersection[j] > 0 and union[j] >= intersection[j]:\n",
    "        intersections += intersection[j]\n",
    "        unions += union[j]\n",
    "\n",
    "    # Compute IOU. Use epsilon to prevent division by zero\n",
    "    iou = np.round(intersections / (unions + tensorflow.keras.backend.epsilon()), 4)\n",
    "    # This must match the type used in py_func\n",
    "    iou = iou.astype(np.float32)\n",
    "    return iou\n",
    "\n",
    "def IoU(y_true, y_pred):\n",
    "    iou = tensorflow.py_function(IOU, [y_true, y_pred], Tout=tensorflow.float32)\n",
    "    return iou\n",
    "\n",
    "model = create_model(False) # Arg is False, if you want to freeze lower layers for fast training (but low accuracy)\n",
    "model.summary() # Print summary\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[IoU]) # Regression loss is MSE\n",
    "\n",
    "# Use earlystopping\n",
    "callback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_IoU', patience=5, min_delta=0.01)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(np.array(data_img),np.array(labels),batch_size=15, epochs = 20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.layers import Input,Conv2D,Dense\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "##############################################\n",
    "def freeze_layers(model_given):\n",
    "    for each in model_given.layers:\n",
    "        each.trainable=False\n",
    "##############################################        \n",
    "\n",
    "model=Sequential()\n",
    "model.add(Input(shape=(224,224,3)))\n",
    "vgg_into=VGG16(weights='imagenet', include_top=False)\n",
    "freeze_layers(vgg_into)\n",
    "model.add(vgg_into)\n",
    "model.add(Conv2D(filters=8,kernel_size=4,activation=\"relu\"))\n",
    "model.add(Dense(8,activation=\"softmax\"))\n",
    "model.add(Conv2D(filters=4,kernel_size=4,activation=\"relu\"))\n",
    "model.add(Dense(4,activation=\"softmax\"))\n",
    "sgd = optimizers.SGD(learning_rate = 0.01,momentum=0.3)\n",
    "model.compile(optimizer = \"adam\", loss = 'mse')\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
